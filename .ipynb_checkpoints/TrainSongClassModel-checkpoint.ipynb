{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from os import listdir\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note types\n",
    "- 0: nothing\n",
    "- 1: step\n",
    "- 2: hold start\n",
    "- 3: hold/roll end\n",
    "- 4: roll start\n",
    "- M: mine\n",
    "\n",
    "# Classes\n",
    "- 0: nothing\n",
    "- 1: one note\n",
    "- 2: two notes\n",
    "- 3: three or four notes\n",
    "- 4: hold start\n",
    "- 5: roll start\n",
    "- 6: mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_back_included = 8\n",
    "num_classes = 7\n",
    "num_features = 44\n",
    "num_features_total = (num_features * samples_back_included)\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, index):\n",
    "    return beat_features[index] if index >= 0 else [0] * num_features\n",
    "\n",
    "def get_class_for_index_expanded(notes, index):\n",
    "    if index < 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    row = notes[index][0]\n",
    "    (steps, holds, rolls, mines) = [row.count(char) for char in ['1', '2', '4', 'M']]\n",
    "    if steps == 0 and mines == 0 and holds == 0 and rolls == 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    steps += (holds + rolls)\n",
    "    return [int(i) for i in [False, steps == 1, steps == 2, steps > 2, holds > 0, rolls > 0, mines > 0]]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    classes_expanded = get_class_for_index_expanded(notes, index)\n",
    "    return [i for i in range(7) if classes_expanded[i]]\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(X, y, key):\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        num_notes = min(len(notes), len(beat_features))\n",
    "        new_beat_features = []\n",
    "        for beat_feature_row, i in zip(beat_features, range(len(beat_features))):\n",
    "            new_beat_feature_row = np.concatenate((beat_feature_row, [i % 48, get_beat_importance(i), i / 48, num_notes - i / 48]), axis=0)\n",
    "            new_beat_features.append(new_beat_feature_row)\n",
    "\n",
    "        for i in range(num_notes):\n",
    "            class_num = get_class_for_index_expanded(notes, i)\n",
    "            features = [feature for j in range(samples_back_included) for feature in get_features_for_index(new_beat_features, i - j)]\n",
    "            X.append(features)\n",
    "            y.append(class_num)\n",
    "\n",
    "def build_training_data(songs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for song_data in songs:\n",
    "        get_features_for_song(X, y, song_data[0], is_full)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 1min 3s, total: 2min 39s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Total 243 songs\n",
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "np.random.shuffle(songs_to_use)\n",
    "\n",
    "X_train, y_train = build_training_data(songs_to_use[:194])\n",
    "X_test, y_test = build_training_data(songs_to_use[194:])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], samples_back_included, num_features))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], samples_back_included, num_features))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 491520 samples, validate on 99328 samples\n",
      "Epoch 1/10\n",
      "491520/491520 [==============================] - 289s - loss: 0.8087 - acc: 0.8598 - val_loss: 0.5723 - val_acc: 0.8907\n",
      "Epoch 2/10\n",
      "491520/491520 [==============================] - 289s - loss: 0.5095 - acc: 0.8796 - val_loss: 0.4797 - val_acc: 0.8910\n",
      "Epoch 3/10\n",
      "491520/491520 [==============================] - 286s - loss: 0.4479 - acc: 0.8811 - val_loss: 0.4330 - val_acc: 0.8921\n",
      "Epoch 4/10\n",
      "491520/491520 [==============================] - 287s - loss: 0.4220 - acc: 0.8816 - val_loss: 0.4183 - val_acc: 0.8939\n",
      "Epoch 5/10\n",
      "491520/491520 [==============================] - 287s - loss: 0.4072 - acc: 0.8829 - val_loss: 0.4115 - val_acc: 0.8927\n",
      "Epoch 6/10\n",
      "491520/491520 [==============================] - 310s - loss: 0.3975 - acc: 0.8834 - val_loss: 0.4131 - val_acc: 0.8900\n",
      "Epoch 7/10\n",
      "491520/491520 [==============================] - 416s - loss: 0.3904 - acc: 0.8840 - val_loss: 0.3997 - val_acc: 0.8924\n",
      "Epoch 8/10\n",
      "491520/491520 [==============================] - 436s - loss: 0.3849 - acc: 0.8846 - val_loss: 0.3975 - val_acc: 0.8932\n",
      "Epoch 9/10\n",
      "491520/491520 [==============================] - 264s - loss: 0.3808 - acc: 0.8851 - val_loss: 0.3983 - val_acc: 0.8922\n",
      "Epoch 10/10\n",
      "491520/491520 [==============================] - 244s - loss: 0.3773 - acc: 0.8855 - val_loss: 0.3994 - val_acc: 0.8924\n",
      "99264/99328 [============================>.] - ETA: 0s[0.39941928889266376, 0.89238683956185572]\n",
      "CPU times: user 1h 6min 37s, sys: 2min 28s, total: 1h 9min 5s\n",
      "Wall time: 52min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, batch_input_shape=[64, samples_back_included, num_features], stateful=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softsign'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train[:491520], y_train[:491520], nb_epoch=10, batch_size=64, verbose=1, validation_data=(X_test[:99328], y_test[:99328]))\n",
    "print (model.evaluate(X_test[:99328], y_test[:99328], batch_size=64))\n",
    "model.save('models/song_class_ltsm_batch64.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try more lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_back_included = 25\n",
    "num_classes = 7\n",
    "num_features = 44\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, index):\n",
    "    return beat_features[index] if index >= 0 else [0] * num_features\n",
    "\n",
    "def get_class_for_index_expanded(notes, index):\n",
    "    if index < 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    row = notes[index][0]\n",
    "    (steps, holds, rolls, mines) = [row.count(char) for char in ['1', '2', '4', 'M']]\n",
    "    if steps == 0 and mines == 0 and holds == 0 and rolls == 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    steps += (holds + rolls)\n",
    "    return [int(i) for i in [False, steps == 1, steps == 2, steps > 2, holds > 0, rolls > 0, mines > 0]]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    classes_expanded = get_class_for_index_expanded(notes, index)\n",
    "    return [i for i in range(7) if classes_expanded[i]]\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(X, y, key):\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        num_notes = min(len(notes), len(beat_features))\n",
    "        new_beat_features = []\n",
    "        for beat_feature_row, i in zip(beat_features, range(len(beat_features))):\n",
    "            new_beat_feature_row = np.concatenate((beat_feature_row, [i % 48, get_beat_importance(i), i / 48, num_notes - i / 48]), axis=0)\n",
    "            new_beat_features.append(new_beat_feature_row)\n",
    "\n",
    "        for i in range(num_notes):\n",
    "            class_num = get_class_for_index_expanded(notes, i)\n",
    "            features = [feature for j in range(samples_back_included) for feature in get_features_for_index(new_beat_features, i - j)]\n",
    "            X.append(features)\n",
    "            y.append(class_num)\n",
    "\n",
    "def build_training_data(songs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for song_data in songs:\n",
    "        get_features_for_song(X, y, song_data[0])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 59s, sys: 4min 50s, total: 8min 49s\n",
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Total 243 songs\n",
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "np.random.shuffle(songs_to_use)\n",
    "\n",
    "X_train, y_train = build_training_data(songs_to_use[:194])\n",
    "X_test, y_test = build_training_data(songs_to_use[194:])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], samples_back_included, num_features))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], samples_back_included, num_features))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 477952 samples, validate on 123264 samples\n",
      "Epoch 1/8\n",
      "477952/477952 [==============================] - 599s - loss: 0.8238 - acc: 0.8533 - val_loss: 0.5551 - val_acc: 0.8819\n",
      "Epoch 2/8\n",
      "477952/477952 [==============================] - 515s - loss: 0.5197 - acc: 0.8809 - val_loss: 0.4534 - val_acc: 0.8823\n",
      "Epoch 3/8\n",
      "477952/477952 [==============================] - 509s - loss: 0.4561 - acc: 0.8824 - val_loss: 0.4333 - val_acc: 0.8787\n",
      "Epoch 4/8\n",
      "477952/477952 [==============================] - 521s - loss: 0.4275 - acc: 0.8835 - val_loss: 0.4145 - val_acc: 0.8814\n",
      "Epoch 5/8\n",
      "477952/477952 [==============================] - 511s - loss: 0.4105 - acc: 0.8846 - val_loss: 0.4195 - val_acc: 0.8811\n",
      "Epoch 6/8\n",
      "477952/477952 [==============================] - 511s - loss: 0.3989 - acc: 0.8856 - val_loss: 0.4064 - val_acc: 0.8797\n",
      "Epoch 7/8\n",
      "477952/477952 [==============================] - 513s - loss: 0.3905 - acc: 0.8864 - val_loss: 0.4117 - val_acc: 0.8763\n",
      "Epoch 8/8\n",
      "477952/477952 [==============================] - 517s - loss: 0.3834 - acc: 0.8871 - val_loss: 0.3953 - val_acc: 0.8809\n",
      "123264/123264 [==============================] - 39s    \n",
      "[0.39533668000982186, 0.88088979750778817]\n",
      "CPU times: user 2h 12min 48s, sys: 5min 56s, total: 2h 18min 44s\n",
      "Wall time: 1h 10min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, batch_input_shape=[64, samples_back_included, num_features], stateful=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softsign'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad', # try adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_cutoff = int(len(X_train) / 64) * 64\n",
    "test_cutoff = int(len(X_test) / 64) * 64\n",
    "model.fit(X_train[:train_cutoff], y_train[:train_cutoff], nb_epoch=8, batch_size=64, verbose=1, validation_data=(X_test[:test_cutoff], y_test[:test_cutoff]))\n",
    "print (model.evaluate(X_test[:test_cutoff], y_test[:test_cutoff], batch_size=64))\n",
    "model.save('models/song_class_ltsm_batch64.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 477952 samples, validate on 123264 samples\n",
      "Epoch 1/2\n",
      "477952/477952 [==============================] - 1546s - loss: 0.8117 - acc: 0.8641 - val_loss: 0.5675 - val_acc: 0.8821\n",
      "Epoch 2/2\n",
      "477952/477952 [==============================] - 1286s - loss: 0.5101 - acc: 0.8822 - val_loss: 0.4689 - val_acc: 0.8824\n",
      "123264/123264 [==============================] - 94s    \n",
      "[0.46890319313618006, 0.88242309190031154]\n",
      "CPU times: user 1h 23min 53s, sys: 5min 41s, total: 1h 29min 35s\n",
      "Wall time: 48min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, batch_input_shape=[64, samples_back_included, num_features], stateful=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softsign'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_cutoff = int(len(X_train) / 64) * 64\n",
    "test_cutoff = int(len(X_test) / 64) * 64\n",
    "model.fit(X_train[:train_cutoff], y_train[:train_cutoff], nb_epoch=2, batch_size=64, verbose=1, validation_data=(X_test[:test_cutoff], y_test[:test_cutoff]))\n",
    "print (model.evaluate(X_test[:test_cutoff], y_test[:test_cutoff], batch_size=64))\n",
    "model.save('models/song_class_ltsm_batch64.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test specific intervals for lookback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples_back_included_indices = [0, 1, 2, 3, 4, 6, 8, 9, 12, 16, 24, 36, 48]\n",
    "samples_back_included = len(samples_back_included_indices)\n",
    "num_classes = 7\n",
    "num_features = 44\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, index):\n",
    "    return beat_features[index] if index >= 0 else [0] * num_features\n",
    "\n",
    "def get_class_for_index_expanded(notes, index):\n",
    "    if index < 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    row = notes[index][0]\n",
    "    (steps, holds, rolls, mines) = [row.count(char) for char in ['1', '2', '4', 'M']]\n",
    "    if steps == 0 and mines == 0 and holds == 0 and rolls == 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    steps += (holds + rolls)\n",
    "    return [int(i) for i in [False, steps == 1, steps == 2, steps > 2, holds > 0, rolls > 0, mines > 0]]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    classes_expanded = get_class_for_index_expanded(notes, index)\n",
    "    return [i for i in range(7) if classes_expanded[i]]\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(X, y, key):\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        num_notes = min(len(notes), len(beat_features))\n",
    "        new_beat_features = []\n",
    "        for beat_feature_row, i in zip(beat_features, range(len(beat_features))):\n",
    "            new_beat_feature_row = np.concatenate((beat_feature_row, [i % 48, get_beat_importance(i), i / 48, num_notes - i / 48]), axis=0)\n",
    "            new_beat_features.append(new_beat_feature_row)\n",
    "\n",
    "        for i in range(num_notes):\n",
    "            class_num = get_class_for_index_expanded(notes, i)\n",
    "            features = [feature for j in samples_back_included_indices for feature in get_features_for_index(new_beat_features, i - j)]\n",
    "            X.append(features)\n",
    "            y.append(class_num)\n",
    "\n",
    "def build_training_data(songs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for song_data in songs:\n",
    "        get_features_for_song(X, y, song_data[0])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 59s, sys: 4min 50s, total: 8min 49s\n",
      "Wall time: 18min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Total 243 songs\n",
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "np.random.shuffle(songs_to_use)\n",
    "\n",
    "X_train, y_train = build_training_data(songs_to_use[:194])\n",
    "X_test, y_test = build_training_data(songs_to_use[194:])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], samples_back_included, num_features))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], samples_back_included, num_features))\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 477952 samples, validate on 123264 samples\n",
      "Epoch 1/2\n",
      "477952/477952 [==============================] - 1546s - loss: 0.8117 - acc: 0.8641 - val_loss: 0.5675 - val_acc: 0.8821\n",
      "Epoch 2/2\n",
      "477952/477952 [==============================] - 1286s - loss: 0.5101 - acc: 0.8822 - val_loss: 0.4689 - val_acc: 0.8824\n",
      "123264/123264 [==============================] - 94s    \n",
      "[0.46890319313618006, 0.88242309190031154]\n",
      "CPU times: user 1h 23min 53s, sys: 5min 41s, total: 1h 29min 35s\n",
      "Wall time: 48min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(128, batch_input_shape=[64, samples_back_included, num_features], stateful=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softsign'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "train_cutoff = int(len(X_train) / 64) * 64\n",
    "test_cutoff = int(len(X_test) / 64) * 64\n",
    "model.fit(X_train[:train_cutoff], y_train[:train_cutoff], nb_epoch=2, batch_size=64, verbose=1, validation_data=(X_test[:test_cutoff], y_test[:test_cutoff]))\n",
    "print (model.evaluate(X_test[:test_cutoff], y_test[:test_cutoff], batch_size=64))\n",
    "model.save('models/song_class_ltsm_batch64.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
