{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "from os import listdir, rename\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs_to_step = ['Anubis', 'Bend Your Mind', 'Boogie Down', 'Bouff', 'Bubble Dancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_rate_down = 1\n",
    "hop_length_down = 8\n",
    "sr = 11025 * 16 / sample_rate_down\n",
    "hop_length = 512 / (sample_rate_down * hop_length_down)\n",
    "samples_per_beat = 24 / 4\n",
    "steps_per_bar = 24\n",
    "class SongFile:\n",
    "    # misc includes\n",
    "    # - offset\n",
    "    # - bpm\n",
    "    def load_misc_from_music(self, y):\n",
    "        _, beat_frames = librosa.beat.beat_track(y=y, sr=sr, hop_length=hop_length)\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr, hop_length=hop_length)\n",
    "        self.offset = beat_times[0]\n",
    "        self.bpm = get_beats(beat_times, beat_frames)\n",
    "\n",
    "    def calculate_indices(self, y):\n",
    "        # take samples_per_beat samples for each beat (need 3rds, 8ths)\n",
    "        seconds = len(y) / sr\n",
    "        num_samples = int(seconds * samples_per_beat * self.bpm / 60)\n",
    "        beat_length = 60. / self.bpm\n",
    "        sample_length = beat_length / samples_per_beat\n",
    "        \n",
    "        if self.offset < 0:\n",
    "            self.offset += 4 * beat_length\n",
    "        \n",
    "        sample_times = [self.offset + (sample_length * i) for i in range(num_samples)]\n",
    "        # only take samples where music still playing\n",
    "        self.indices = [round(time * sr) for time in sample_times if round(time * sr) < len(y)]\n",
    "        \n",
    "    def calculate_features(self, y):\n",
    "        y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "        beat_frames = librosa.samples_to_frames(self.indices)\n",
    "\n",
    "        # Compute MFCC features from the raw signal\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "\n",
    "        # And the first-order differences (delta features)\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "\n",
    "        # Stack and synchronize between beat events\n",
    "        # This time, we'll use the mean value (default) instead of median\n",
    "        beat_mfcc_delta = librosa.feature.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)\n",
    "\n",
    "        # Compute chroma features from the harmonic signal\n",
    "        chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "\n",
    "        # Aggregate chroma features between beat events\n",
    "        # We'll use the median value of each feature between beat frames\n",
    "        beat_chroma = librosa.feature.sync(chromagram, beat_frames, aggregate=np.median)\n",
    "\n",
    "        custom_hop = 256\n",
    "        onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=custom_hop)\n",
    "        onsets = librosa.onset.onset_detect(y=y, sr=sr, onset_envelope=onset_env, hop_length=custom_hop)\n",
    "\n",
    "        i = 0\n",
    "        onset_happened_in_frame = [0] * (len(self.indices) + 1)\n",
    "        for onset in onsets:\n",
    "            onset_scaled = onset * custom_hop\n",
    "            while abs(onset_scaled - self.indices[i]) > abs(onset_scaled - self.indices[i + 1]):\n",
    "                i += 1\n",
    "            onset_happened_in_frame[i] = max(onset_env[onset], onset_env[onset + 1], onset_env[onset + 2], onset_env[onset + 3], onset_env[onset + 4])\n",
    "\n",
    "        indices = [0]\n",
    "        indices.extend(self.indices)\n",
    "        max_offset_bounds = [(int(indices[i] / custom_hop), int(indices[i + 1] / custom_hop)) for i in range(len(indices) - 1)]\n",
    "        max_offset_strengths = [max(onset_env[bounds[0]:bounds[1]]) for bounds in max_offset_bounds]\n",
    "        max_offset_strengths.append(0)\n",
    "\n",
    "        # Finally, stack all beat-synchronous features together\n",
    "        self.beat_features = np.vstack([beat_chroma, beat_mfcc_delta, [onset_happened_in_frame, max_offset_strengths]])\n",
    "\n",
    "    def __init__(self, key, folder, music_file, load_type):\n",
    "        key = key\n",
    "        self.folder = folder\n",
    "        self.music_file = music_file\n",
    "        y = None\n",
    "        print ('Loading song {0}'.format(key))\n",
    "        \n",
    "        if load_type == 'from_music' or load_type == 'from_stepfile':\n",
    "            if load_type == 'from_music':\n",
    "                print ('Loading music')\n",
    "                y, _ = librosa.load(self.music_file, sr=sr)\n",
    "                print ('Calculating misc from music')\n",
    "                self.load_misc_from_music(y)\n",
    "            else:\n",
    "                print ('Loading misc from stepfile')\n",
    "                self.load_misc_from_stepfile()\n",
    "                if self.bpm == 0:\n",
    "                    raise Exception('Inconsistent bpm')\n",
    "                print ('Loading music')\n",
    "                y, _ = librosa.load(self.music_file, sr=sr)\n",
    "                \n",
    "\n",
    "            print ('Calculating indices')\n",
    "            self.calculate_indices(y)\n",
    "            print ('Calculating features')\n",
    "            self.calculate_features(y)\n",
    "            print ('Saving song\\n')\n",
    "            pd.DataFrame([self.offset, self.bpm]).to_csv('data/{0}_misc.csv'.format(key), index=False)\n",
    "            pd.DataFrame(self.beat_features).to_csv('data/{0}_beat_features.csv'.format(key), index=False)\n",
    "            \n",
    "        if load_type == 'from_store':\n",
    "            if not '{0}_beat_features.csv'.format(key) in listdir('data'):\n",
    "                print ('Song hasnt been loaded yet')\n",
    "            else:\n",
    "                [self.offset], [self.bpm] = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "                self.beat_features = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "\n",
    "\n",
    "# # Some useful functions to load induvidual or lists of songs\n",
    "# - load_song(pack: String, pack: String, force_new: Bool)\n",
    "# - load_songs(songs: Array(Pair(String~pack, String~title)), force_new: Bool)\n",
    "# - load_all_songs(force_new: Bool)\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "def load_songs(songs, load_type):\n",
    "    return {'{0}~{1}'.format(song[0], song[1]): SongFile(song[0], song[1], load_type) for song in songs}\n",
    "\n",
    "# # Functions to get bpm from song\n",
    "# - get_beats(beat_times: Array(Float), beat_frames: Array(Int))\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "def get_beats(beat_times, beat_frames):\n",
    "    changes = []\n",
    "    changes_time = []\n",
    "    for i in range(len(beat_frames) - 1):\n",
    "        changes.append(beat_frames[i + 1] - beat_frames[i])\n",
    "        changes_time.append(beat_times[i + 1] - beat_times[i])\n",
    "\n",
    "    sorted_changes = sorted(changes)\n",
    "    median = sorted_changes[int(len(changes) / 2)]\n",
    "    median = max(set(sorted_changes), key=sorted_changes.count)\n",
    "\n",
    "    changes_counted = [False] * len(changes)\n",
    "    time_changes_sum = 0\n",
    "    time_changes_count = 0\n",
    "    for i in range(len(changes)):\n",
    "        # can use other factors (eg if song has a slow part take double beats into accout)\n",
    "        # in [0.5, 1, 2]:\n",
    "        for change_factor in [1]:\n",
    "            if abs((changes[i] * change_factor) - median) <= hop_length_down:\n",
    "                changes_counted[i] = True\n",
    "                time_changes_sum += (changes_time[i] * change_factor)\n",
    "                time_changes_count += change_factor\n",
    "            \n",
    "    average = time_changes_sum / time_changes_count\n",
    "    \n",
    "    time_differences = []\n",
    "    earliest_proper_beat = 1\n",
    "    for i in range(1, len(beat_times) - 1):\n",
    "        if changes_counted[i] & changes_counted[i - 1]:\n",
    "            earliest_proper_beat = i\n",
    "            break\n",
    "            \n",
    "    last_proper_beat = len(beat_times) -2\n",
    "    for i in range(1, len(beat_times) - 1):\n",
    "        if changes_counted[len(beat_times) - i - 1] & changes_counted[len(beat_times) - i - 2]:\n",
    "            last_proper_beat = len(beat_times) - i - 1\n",
    "            break\n",
    "    \n",
    "    time_differences = []\n",
    "    buffer = 5\n",
    "    for i in range(20):\n",
    "        start_beat = earliest_proper_beat + buffer * i\n",
    "        if changes_counted[start_beat] & changes_counted[start_beat - 1]:\n",
    "            for j in range(20):\n",
    "                end_beat = last_proper_beat - buffer * j\n",
    "                if changes_counted[end_beat] & changes_counted[end_beat - 1]:\n",
    "                    time_differences.append(beat_times[end_beat] - beat_times[start_beat])\n",
    "        \n",
    "    # get num beats, round, and make new average\n",
    "    new_averages = [time_difference / round(time_difference / average) for time_difference in time_differences]\n",
    "    #print (new_averages)\n",
    "    new_averages.sort()\n",
    "    num_averages = len(new_averages)\n",
    "    #new_average = sum(new_averages[5:num_averages - 5]) / (num_averages - 10)\n",
    "    new_average = new_averages[int(num_averages/2)]\n",
    "    bpm = 60./new_average\n",
    "    while bpm >= 200:\n",
    "        bpm /= 2\n",
    "    while bpm < 100:\n",
    "        bpm *= 2\n",
    "    return bpm\n",
    "\n",
    "def get_song_data(key):\n",
    "    pack, song = key.split('~')\n",
    "    folder = 'StepMania/Songs/{0}/{1}/'.format(pack, song)\n",
    "    musicfiles = [file for file in listdir(folder) if file.endswith('.ogg') or file.endswith('.mp3')]\n",
    "    music = folder + musicfiles[0]\n",
    "    \n",
    "    return [key, folder, music]\n",
    "\n",
    "def get_song_features(key):\n",
    "    song_data = get_song_data(key)\n",
    "    if '{0}_beat_features.csv'.format(song_data[0]) in listdir('data'):\n",
    "        print ('Song Already Loaded')\n",
    "    else:\n",
    "        SongFile(song_data[0], song_data[1], song_data[2], 'from_stepfile')\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song Already Loaded\n",
      "Song Already Loaded\n",
      "Song Already Loaded\n",
      "Song Already Loaded\n",
      "Song Already Loaded\n"
     ]
    }
   ],
   "source": [
    "for song_name in songs_to_step:\n",
    "    get_song_features('a_test~{0}'.format(song_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 8\n",
    "num_classes = 5\n",
    "num_features = 40\n",
    "num_features_total = (num_features * samples_back_included) + 4\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, index):\n",
    "    if index < 0:\n",
    "        return [0] * num_features\n",
    "    return beat_features[index]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    if index < 0:\n",
    "        return (0, 0)\n",
    "    return notes[index][0].count('1')\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(key):\n",
    "    X = []\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        num_notes = len(beat_features)\n",
    "        for i in range(num_notes):\n",
    "            features = [feature for j in range(samples_back_included) for feature in get_features_for_index(beat_features, i - j)]\n",
    "            features.append(i % 48)\n",
    "            features.append(get_beat_importance(i))\n",
    "            features.append(i / 48)\n",
    "            features.append(num_notes - i / 48)\n",
    "            X.append(features)\n",
    "    return np.array(X)\n",
    "\n",
    "def calculate_importance(row):\n",
    "    return (1 - row[0]) * (row[1] + row[2] * 2 + row[3] * 30 + row[4] * 40)\n",
    "\n",
    "def step_song(key, clf):\n",
    "    song_X = get_features_for_song(key)\n",
    "    new_song_y = clf.predict(song_X)\n",
    "    beat_importance = [calculate_importance(row) for row in new_song_y]\n",
    "    \n",
    "    pd.DataFrame(beat_importance).to_csv('generated_data/{0}_importance_generated.csv'.format(key), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beat_feature_model = load_model('models/beat_importance_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for song_name in songs_to_step:\n",
    "    step_song('a_test~{0}'.format(song_name), beat_feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps_per_bar = 48\n",
    "class WriteSongFile:\n",
    "    def __init__(self, key, folder, music_file):\n",
    "        misc = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "        self.beat_importance = pd.read_csv('generated_data/{0}_importance_generated.csv'.format(key), converters={'0': lambda x: float(x)}).values\n",
    "        self.folder = folder\n",
    "        self.name = key.split('~')[1]\n",
    "        self.music_name = music_file\n",
    "        self.offset = misc[0][0]\n",
    "        self.beat_length = 60. / misc[1][0]\n",
    "        self.bpm = misc[1][0]\n",
    "        self.extension = music_file.split('.')[1]\n",
    "\n",
    "songs = {}\n",
    "for song_name in songs_to_step:\n",
    "    key = 'a_test~{0}'.format(song_name)\n",
    "    song_data = get_song_data(key)\n",
    "    songs[key] = WriteSongFile(key, song_data[1], song_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beats_to_track = 48\n",
    "num_classes = 3\n",
    "class_map = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 1,\n",
    "    '3': 0,\n",
    "    '4': 1,\n",
    "    'M': 2\n",
    "}\n",
    "\n",
    "def get_is_note(i, notes):\n",
    "    if i < 0:\n",
    "        return [0, 0, 0, 0]\n",
    "    return [char == '1' for char in notes[i][0]]\n",
    "\n",
    "def get_is_mine(i, notes):\n",
    "    if i < 0:\n",
    "        return [0, 0, 0, 0]\n",
    "    return [char == 'M' for char in notes[i][0]]\n",
    "\n",
    "def get_note_class(note):\n",
    "    if i < 0:\n",
    "        return 0\n",
    "    return class_map[note] if note in class_map else 0\n",
    "\n",
    "def get_row_classes(row):\n",
    "    return [get_note_class(note) for note in row[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: build models for either side instead of one left one right\n",
    "models = [load_model('models/no_filter_10_data_step_model_{0}.h5'.format(i)) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: 'M'\n",
    "}\n",
    "# TODO: make 3/4's less common by penalizing here or figure out how in model\n",
    "def get_output_for_note(note_class_predictions):\n",
    "    note_class_predictions[1] *= 1.5\n",
    "    return outputs[np.argmax(note_class_predictions)]\n",
    "\n",
    "def get_output_for_row(note_class_predictions):\n",
    "    return ''.join([get_output_for_note(note[0]) for note in note_class_predictions])\n",
    "\n",
    "def get_output(song):\n",
    "    y = []\n",
    "    length = len(song.beat_importance)\n",
    "    is_note = [[0, 0, 0, 0]] * beats_to_track\n",
    "    is_mine = [[0, 0, 0, 0]] * beats_to_track\n",
    "    importances = [0 if i < 0 else song.beat_importance[i][0] for i in range(-beats_to_track, length)]\n",
    "    for i in range(length):\n",
    "        X_row = np.concatenate((np.array(is_note[-(beats_to_track - 1):]).flatten(), np.array(is_mine[-(beats_to_track - 1):]).flatten(), importances[i:i + beats_to_track]), axis=0)\n",
    "        notes = [models[i].predict(np.array([X_row])) for i in range(4)]\n",
    "        prediction = get_output_for_row(notes)\n",
    "        is_note.append([char == '1' for char in prediction])\n",
    "        is_mine.append([char == 'M' for char in prediction])\n",
    "        y.append(prediction)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_song_header(output_stepfile, song):\n",
    "    keys = ['TITLE', 'MUSIC', 'OFFSET', 'SAMPLESTART', 'SAMPLELENGTH', 'SELECTABLE', 'BPMS']\n",
    "    header_info = {\n",
    "        'TITLE': song.name,\n",
    "        'MUSIC': '{0}.{1}'.format(song.name, song.extension),\n",
    "        'OFFSET': -song.offset,\n",
    "        'SAMPLESTART': song.offset + 32 * song.beat_length,\n",
    "        'SAMPLELENGTH': 32 * song.beat_length,\n",
    "        'SELECTABLE': 'YES',\n",
    "        'BPMS': '0.000={:.3f}'.format(song.bpm)\n",
    "    }\n",
    "    \n",
    "    for key in keys:\n",
    "        print (\"#{0}:{1};\".format(key, str(header_info[key])), file=output_stepfile)\n",
    "        \n",
    "def write_step_header(output_stepfile, song):\n",
    "    print(\"\\n//---------------dance-single - J. Zukewich----------------\", file=output_stepfile)\n",
    "    print (\"#NOTES:\", file=output_stepfile)\n",
    "    for detail in ['dance-single', 'J. Zukewich', 'Expert', '9', '0.242,0.312,0.204,0.000,0.000']:\n",
    "        print ('\\t{0}:'.format(detail), file=output_stepfile)\n",
    "    \n",
    "    for i in range(len(song.predicted_notes)):\n",
    "        row = song.predicted_notes[i]\n",
    "        print (row, file=output_stepfile)\n",
    "        if i % steps_per_bar == steps_per_bar - 1:\n",
    "            print (\",\", file=output_stepfile)\n",
    "\n",
    "    print (\"0000;\", file=output_stepfile)\n",
    "    \n",
    "def step_song(song):\n",
    "    stepfile_name = 'StepMania/Songs/a_test/{0}/{0}.sm'.format(song.name)\n",
    "    output_stepfile=open(stepfile_name, 'w')\n",
    "    write_song_header(output_stepfile, song)\n",
    "    write_step_header(output_stepfile, song)\n",
    "    output_stepfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for song_name in songs_to_step:\n",
    "    song = songs['a_test~{0}'.format(song_name)]\n",
    "    song.predicted_notes = get_output(song)\n",
    "    step_song(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
