{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instead of training models for each note\n",
    "- decide which will have notes, for now pick x with one, y with another (train model for this + holds, hands, mines, rolls etc later)\n",
    "- for each note that will have something, decide what combo it has (train from prev notes (not all 48, pick more relevant ones)) (4 for one note, 6 for 2, 4 for 3) and pick highest class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS\n",
    "- test using all info from get_beat_importance instead of aggregate to decide on 1, 2, etc notes (culd also try to predict hold/roll there (would need to train on later beat info as well))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_bar = 48\n",
    "class SongFile:\n",
    "    def __init__(self, key, folder, stepfile, music_file):\n",
    "        misc = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "        self.note_classes = pd.read_csv('generated_data/{0}_note_classes_generated.csv'.format(key), converters={'0': lambda x: float(x)}).values\n",
    "        self.notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        self.folder = folder\n",
    "        self.name = key.split('~')[1]\n",
    "        self.music_name = music_file\n",
    "        self.stepfile_name = stepfile\n",
    "        self.offset = misc[0][0]\n",
    "        self.beat_length = 60. / misc[1][0]\n",
    "        self.bpm = misc[1][0]\n",
    "        self.extension = music_file.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "save_files = listdir('data')\n",
    "save_files_generated = listdir('generated_data')\n",
    "songs = {}\n",
    "for song_data in songs_to_use:\n",
    "    key = song_data[0]\n",
    "    if '{0}_misc.csv'.format(key) in save_files and '{0}_note_classes_generated.csv'.format(key) in save_files_generated:\n",
    "        songs[key] = SongFile(key, song_data[1], song_data[2], song_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beats_to_track = 48\n",
    "num_classes_one_note = 4\n",
    "num_classes_two_note = 6\n",
    "class_map_one_note = {\n",
    "    '1000': 0,\n",
    "    '0100': 1,\n",
    "    '0010': 2,\n",
    "    '0001': 3\n",
    "}\n",
    "class_reverse_map_one_note = ['1000', '0100', '0010', '0001']\n",
    "\n",
    "class_map_two_note = {\n",
    "    '1001': 0,\n",
    "    '0110': 1,\n",
    "    '1100': 2,\n",
    "    '1010': 3,\n",
    "    '0101': 4,\n",
    "    '0011': 5\n",
    "}\n",
    "class_reverse_map_two_note = ['1001', '0110', '1100', '1010', '0101', '0011']\n",
    "\n",
    "note_types = ['0', '1', 'M', '2', '4', '3']\n",
    "\n",
    "def get_features_for_row(row):\n",
    "    return [int(char == target) for target in note_types for char in row]\n",
    "\n",
    "important_indices = [1, 2, 3, 4, 6, 8, 12, 18, 24, 36, 48]\n",
    "def get_features(index, features, note_classes):\n",
    "    indices = [index + beats_to_track - i for i in important_indices]\n",
    "    return np.array([np.concatenate((note_classes[i], features[i]), axis = 0) for i in indices]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_one_note = []\n",
    "y_one_note = []\n",
    "X_two_note = []\n",
    "y_two_note = []\n",
    "for key in songs:\n",
    "    note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * beats_to_track), songs[key].note_classes), axis = 0)\n",
    "    notes = np.concatenate((([['0000']] * beats_to_track), songs[key].notes), axis = 0)\n",
    "    if abs(len(note_classes) - len(notes) > 250):\n",
    "        print ('Lengths dont match for {0}'.format(key))\n",
    "        print ('{0} vs {1}'.format(len(note_classes), len(notes)))\n",
    "        continue\n",
    "    length = min(len(note_classes), len(notes)) - beats_to_track\n",
    "    features = np.array([get_features_for_row(notes[i][0]) for i in range(-beats_to_track, length)])\n",
    "    for i in range(length):\n",
    "        row = notes[i + beats_to_track][0]\n",
    "        (blank, steps, mines, hold_starts, roll_starts, hold_ends) = [row.count(note_type) for note_type in note_types]\n",
    "        if steps == 1 and blank == 3:\n",
    "            X_one_note.append(get_features(i, features, note_classes))\n",
    "            y_one_note.append(class_map_one_note[row])\n",
    "            \n",
    "        if steps == 2 and blank == 2:\n",
    "            X_two_note.append(get_features(i, features, note_classes))\n",
    "            y_two_note.append(class_map_two_note[row])\n",
    "\n",
    "X_one_note = np.array(X_one_note)\n",
    "y_one_note = np.array(y_one_note)\n",
    "X_two_note = np.array(X_two_note)\n",
    "y_two_note = np.array(y_two_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(100, input_dim=275, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(500, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(500, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                               optimizer='adadelta',\n",
    "                               metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_one_note_hot = np.zeros((len(y_one_note), num_classes_one_note))\n",
    "y_one_note_hot[np.arange(len(y_one_note)), y_one_note] = 1\n",
    "y_two_note_hot = np.zeros((len(y_two_note), num_classes_two_note))\n",
    "y_two_note_hot[np.arange(len(y_two_note)), y_two_note] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "73489/73489 [==============================] - 30s - loss: 1.3950 - acc: 0.2699    \n"
     ]
    }
   ],
   "source": [
    "y_one_note_model = build_model(num_classes_one_note)\n",
    "y_one_note_model.fit(X_one_note, y_one_note_hot, nb_epoch=1, batch_size=50)\n",
    "y_one_note_model.save('models/y_one_note_model.h5')\n",
    "# Dense 1000: 63s - loss: 1.3934 - acc: 0.2707\n",
    "# Dense 550: 53s - loss: 1.3903 - acc: 0.2703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5225/5225 [==============================] - 17s - loss: 1.8717 - acc: 0.1883    \n"
     ]
    }
   ],
   "source": [
    "y_two_note_model = build_model(num_classes_two_note) .2746 29s\n",
    "y_two_note_model.fit(X_two_note, y_two_note_hot, nb_epoch=1, batch_size=5)\n",
    "y_two_note_model.save('models/y_two_note_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_importance(i, beat_importance):\n",
    "    surrounding_beats = beat_importance[max(i - 12,0):min(i + 12,len(beat_importance))]\n",
    "    average = sum(surrounding_beats) / float(len(surrounding_beats))\n",
    "    return beat_importance[i] - (average / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = ['1000', '0100', '0001', '0010', '0100', '1000', '0001', '0010']\n",
    "def get_output(song):\n",
    "    predicted_notes = []\n",
    "    length = len(song.beat_importance)\n",
    "    beat_importance = [importance[0] for importance in song.beat_importance]\n",
    "    beat_importance = [normalize_importance(i, beat_importance) for i in range(len(beat_importance))]\n",
    "    beat_importance_sorted = sorted(beat_importance)\n",
    "    one_note_cutoff = beat_importance_sorted[int(0.88 * length)]\n",
    "    two_note_cutoff = beat_importance_sorted[int(0.97 * length)]\n",
    "    dummy_rows = [row for eigth in pattern for row in [eigth] + ['0000'] * 5]\n",
    "    features = [get_features(row) for row in dummy_rows]\n",
    "    for importance in beat_importance:\n",
    "        if importance < one_note_cutoff:\n",
    "            prediction = '0000'\n",
    "        elif importance < two_note_cutoff:\n",
    "            X_row = [np.array(features[-(beats_to_track - 1):]).flatten()]\n",
    "            prediction_values = y_one_note_model.predict(np.array(X_row))\n",
    "            prediction = class_reverse_map_one_note[np.argmax(prediction_values)]\n",
    "        else:\n",
    "            X_row = [np.array(features[-(beats_to_track - 1):]).flatten()]\n",
    "            prediction_values = y_two_note_model.predict(np.array(X_row))\n",
    "            prediction = class_reverse_map_two_note[np.argmax(prediction_values)]\n",
    "\n",
    "        predicted_notes.append(prediction)\n",
    "        features.append(get_features(prediction))\n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song = songs['In The Groove~Lemmings on the Run']\n",
    "song = songs['In The Groove~Infection']\n",
    "song = songs['In The Groove~July']\n",
    "song.predicted_notes = get_output(song)\n",
    "step_song(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_song_header(output_stepfile, song):\n",
    "    keys = ['TITLE', 'MUSIC', 'OFFSET', 'SAMPLESTART', 'SAMPLELENGTH', 'SELECTABLE', 'BPMS']\n",
    "    header_info = {\n",
    "        'TITLE': song.name,\n",
    "        'MUSIC': '{0}.{1}'.format(song.name, song.extension),\n",
    "        'OFFSET': -song.offset,\n",
    "        'SAMPLESTART': song.offset + 32 * song.beat_length,\n",
    "        'SAMPLELENGTH': 32 * song.beat_length,\n",
    "        'SELECTABLE': 'YES',\n",
    "        'BPMS': '0.000={:.3f}'.format(song.bpm)\n",
    "    }\n",
    "    \n",
    "    for key in keys:\n",
    "        print (\"#{0}:{1};\".format(key, str(header_info[key])), file=output_stepfile)\n",
    "        \n",
    "def write_step_header(output_stepfile, song):\n",
    "    print(\"\\n//---------------dance-single - J. Zukewich----------------\", file=output_stepfile)\n",
    "    print (\"#NOTES:\", file=output_stepfile)\n",
    "    for detail in ['dance-single', 'J. Zukewich', 'Expert', '9', '0.242,0.312,0.204,0.000,0.000']:\n",
    "        print ('\\t{0}:'.format(detail), file=output_stepfile)\n",
    "    \n",
    "    for i in range(len(song.predicted_notes)):\n",
    "        row = song.predicted_notes[i]\n",
    "        print (row, file=output_stepfile)\n",
    "        if i % steps_per_bar == steps_per_bar - 1:\n",
    "            print (\",\", file=output_stepfile)\n",
    "\n",
    "    print (\"0000;\", file=output_stepfile)\n",
    "    \n",
    "def step_song(song):\n",
    "    if song.name + '.sm' in os.listdir(song.folder) and not song.name + '.sm.backup' in os.listdir(song.folder):\n",
    "        os.rename(song.stepfile_name, song.stepfile_name + '.backup')\n",
    "            \n",
    "    output_stepfile=open(song.stepfile_name, 'w')\n",
    "    write_song_header(output_stepfile, song)\n",
    "    write_step_header(output_stepfile, song)\n",
    "    output_stepfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
