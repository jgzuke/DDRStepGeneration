{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "## from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "from os import listdir, rename, makedirs\n",
    "from shutil import copyfile\n",
    "from os.path import isfile, join, exists\n",
    "from numpy import median, diff\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get beat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_bar = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_rate_down = 1\n",
    "hop_length_down = 8\n",
    "sr = 11025 * 16 / sample_rate_down\n",
    "hop_length = 512 / (sample_rate_down * hop_length_down)\n",
    "samples_per_beat = steps_per_bar / 4\n",
    "\n",
    "def load_misc_from_music(y):\n",
    "    _, beat_frames = librosa.beat.beat_track(y=y, sr=sr, hop_length=hop_length)\n",
    "    beat_times = librosa.frames_to_time(beat_frames, sr=sr, hop_length=hop_length)\n",
    "    return (beat_times[0], get_beats(beat_times, beat_frames))\n",
    "\n",
    "def get_beats(beat_times, beat_frames):\n",
    "    changes = []\n",
    "    changes_time = []\n",
    "    for i in range(len(beat_frames) - 1):\n",
    "        changes.append(beat_frames[i + 1] - beat_frames[i])\n",
    "        changes_time.append(beat_times[i + 1] - beat_times[i])\n",
    "\n",
    "    sorted_changes = sorted(changes)\n",
    "    median = sorted_changes[int(len(changes) / 2)]\n",
    "    median = max(set(sorted_changes), key=sorted_changes.count)\n",
    "\n",
    "    changes_counted = [False] * len(changes)\n",
    "    time_changes_sum = 0\n",
    "    time_changes_count = 0\n",
    "    for i in range(len(changes)):\n",
    "        # can use other factors (eg if song has a slow part take double beats into accout)\n",
    "        # in [0.5, 1, 2]:\n",
    "        for change_factor in [1]:\n",
    "            if abs((changes[i] * change_factor) - median) <= hop_length_down:\n",
    "                changes_counted[i] = True\n",
    "                time_changes_sum += (changes_time[i] * change_factor)\n",
    "                time_changes_count += change_factor\n",
    "            \n",
    "    average = time_changes_sum / time_changes_count\n",
    "    \n",
    "    time_differences = []\n",
    "    earliest_proper_beat = 1\n",
    "    for i in range(1, len(beat_times) - 1):\n",
    "        if changes_counted[i] & changes_counted[i - 1]:\n",
    "            earliest_proper_beat = i\n",
    "            break\n",
    "            \n",
    "    last_proper_beat = len(beat_times) -2\n",
    "    for i in range(1, len(beat_times) - 1):\n",
    "        if changes_counted[len(beat_times) - i - 1] & changes_counted[len(beat_times) - i - 2]:\n",
    "            last_proper_beat = len(beat_times) - i - 1\n",
    "            break\n",
    "    \n",
    "    time_differences = []\n",
    "    buffer = 5\n",
    "    for i in range(20):\n",
    "        start_beat = earliest_proper_beat + buffer * i\n",
    "        if changes_counted[start_beat] & changes_counted[start_beat - 1]:\n",
    "            for j in range(20):\n",
    "                end_beat = last_proper_beat - buffer * j\n",
    "                if changes_counted[end_beat] & changes_counted[end_beat - 1]:\n",
    "                    time_differences.append(beat_times[end_beat] - beat_times[start_beat])\n",
    "        \n",
    "    # get num beats, round, and make new average\n",
    "    new_averages = [time_difference / round(time_difference / average) for time_difference in time_differences]\n",
    "    new_averages.sort()\n",
    "    num_averages = len(new_averages)\n",
    "    new_average = new_averages[int(num_averages/2)]\n",
    "    bpm = 60./new_average\n",
    "    while bpm >= 200:\n",
    "        bpm /= 2\n",
    "    while bpm < 100:\n",
    "        bpm *= 2\n",
    "    return bpm\n",
    "\n",
    "def calculate_indices(offset, bpm, y):\n",
    "    # take samples_per_beat samples for each beat (need 3rds, 8ths)\n",
    "    seconds = len(y) / sr\n",
    "    num_samples = int(seconds * samples_per_beat * bpm / 60)\n",
    "    beat_length = 60. / bpm\n",
    "    sample_length = beat_length / samples_per_beat\n",
    "\n",
    "    if offset < 0:\n",
    "        offset += 4 * beat_length\n",
    "\n",
    "    sample_times = [offset + (sample_length * i) for i in range(num_samples)]\n",
    "    # only take samples where music still playing\n",
    "    indices = [round(time * sr) for time in sample_times if round(time * sr) < len(y)]\n",
    "    # round down to nearest bar\n",
    "    length = steps_per_bar * int(len(indices) / steps_per_bar) - 1\n",
    "    return indices[:length]\n",
    "\n",
    "def calculate_features(indices, y):\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    beat_frames = librosa.samples_to_frames(indices)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "    mfcc_delta = librosa.feature.delta(mfcc)\n",
    "    beat_mfcc_delta = librosa.feature.sync(np.vstack([mfcc, mfcc_delta]), beat_frames)\n",
    "\n",
    "    chromagram = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "    beat_chroma = librosa.feature.sync(chromagram, beat_frames, aggregate=np.median)\n",
    "\n",
    "    custom_hop = 256\n",
    "    onset_env = librosa.onset.onset_strength(y=y, sr=sr, hop_length=custom_hop)\n",
    "    onsets = librosa.onset.onset_detect(y=y, sr=sr, onset_envelope=onset_env, hop_length=custom_hop)\n",
    "\n",
    "    i = 0\n",
    "    onset_happened_in_frame = [0] * (len(indices) + 1)\n",
    "    for onset in onsets:\n",
    "        onset_scaled = onset * custom_hop\n",
    "        while i + 1 < len(indices) and abs(onset_scaled - indices[i]) > abs(onset_scaled - indices[i + 1]):\n",
    "            i += 1\n",
    "        onset_happened_in_frame[i] = max(onset_env[onset], onset_env[onset + 1], onset_env[onset + 2], onset_env[onset + 3], onset_env[onset + 4])\n",
    "\n",
    "    zero_indexed_indices = [0] + indices\n",
    "    max_offset_bounds = [(int(zero_indexed_indices[i] / custom_hop), int(zero_indexed_indices[i + 1] / custom_hop)) for i in range(len(zero_indexed_indices) - 1)]\n",
    "    max_offset_strengths = [max(onset_env[bounds[0]:bounds[1]]) for bounds in max_offset_bounds]\n",
    "    max_offset_strengths.append(0)\n",
    "\n",
    "    return np.vstack([beat_chroma, beat_mfcc_delta, [onset_happened_in_frame, max_offset_strengths]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get beat importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 8\n",
    "num_features = 40\n",
    "def get_features_for_index(beat_features, index):\n",
    "    if index < 0:\n",
    "        return [0] * num_features\n",
    "    return beat_features[index]\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(beat_features_rotated):\n",
    "    X = []\n",
    "    y = []\n",
    "    beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "    for i in range(len(beat_features)):\n",
    "        features = [feature for j in range(samples_back_included) for feature in get_features_for_index(beat_features, i - j)]\n",
    "        features.append(i % 48)\n",
    "        features.append(get_beat_importance(i))\n",
    "        features.append(i / 48)\n",
    "        features.append(len(beat_features) - i / 48)\n",
    "        X.append(features)\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get song output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "note_types = ['0', '1', 'M', '2', '4', '3']\n",
    "def get_features_for_row(row):\n",
    "    return [int(char == target) for target in note_types for char in row]\n",
    "\n",
    "empty_row = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "def get_previous_notes(index, features):\n",
    "    previous_notes = [features[i] for i in range(index, index + song_padding) if not np.array_equal(features[i], empty_row)]\n",
    "    return [empty_row] * (8 - len(previous_notes)) + previous_notes[-8:]\n",
    "    \n",
    "song_padding = 96\n",
    "song_end_padding = 96\n",
    "important_indices = [1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "important_indices_classes = [-96, -84, -72, -60, -48, -36, -24, -12, 0, 1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "def get_features(index, features, note_classes):\n",
    "    indices = [index + song_padding - i for i in important_indices]\n",
    "    indices_classes = [index + song_padding - i for i in important_indices_classes]\n",
    "    past_classes = np.array([note_classes[i] for i in indices_classes]).flatten()\n",
    "    past_features = np.array([features[i] for i in indices]).flatten()\n",
    "    previous_notes = np.array(get_previous_notes(index, features)).flatten()\n",
    "    return np.concatenate((past_classes, past_features, previous_notes), axis = 0)\n",
    "\n",
    "def get_model_class_for_notes(row):\n",
    "    note_counts = [row.count(note_type) for note_type in note_types]\n",
    "    (blank, steps, mines, hold_starts, roll_starts, hold_ends) = note_counts\n",
    "    \n",
    "    model_classes = []\n",
    "    if steps + hold_starts + roll_starts == 1:\n",
    "        model_classes.append(1)\n",
    "\n",
    "    if steps + hold_starts + roll_starts == 2:\n",
    "        model_classes.append(2)\n",
    "        \n",
    "    if steps + hold_starts + roll_starts > 2:\n",
    "        model_classes.append(3)\n",
    "        \n",
    "    if hold_starts > 0:\n",
    "        model_classes.append(4)\n",
    "        \n",
    "    if roll_starts > 0:\n",
    "        model_classes.append(5)\n",
    "        \n",
    "    if mines > 0:\n",
    "        model_classes.append(6)\n",
    "        \n",
    "    return model_classes\n",
    "\n",
    "def get_model_output_for_class(model_class, row):\n",
    "    if model_class == 1 or model_class == 2 or model_class == 3:\n",
    "        return [int(char == '1' or char == '2' or char == '4') for char in row]\n",
    "    if model_class == 4:\n",
    "        return [int(char == '2') for char in row]\n",
    "    if model_class == 5:\n",
    "        return [int(char == '4') for char in row]\n",
    "    if model_class == 6:\n",
    "        return [int(char == 'M') for char in row]\n",
    "\n",
    "def get_hold_length(notes, note_row, note_column):\n",
    "    i = 0\n",
    "    while i < len(notes) - note_row:\n",
    "        if notes[note_row + i][0][note_column] == '3':\n",
    "            return i\n",
    "        i += 1\n",
    "    return False\n",
    "\n",
    "i = 0\n",
    "surrounding_beat_indices = [i for i in range(-24, 25)]#[-48, -36, -24, -12, 12, 24, 36, 48]\n",
    "def get_average_for_class(surrounding_classes, class_num):\n",
    "    return float(sum([beat_class[class_num] for beat_class in surrounding_classes])) / float(len(surrounding_classes))\n",
    "\n",
    "def normalize_row(beat_class, surrounding_classes):\n",
    "    return [beat_class[class_num] / get_average_for_class(surrounding_classes, class_num) for class_num in range(7)]\n",
    "    \n",
    "def normalize_classes(note_classes):\n",
    "    return [normalize_row(note_classes[i], note_classes[max(0, i - 24):min(len(note_classes), i + 24)]) for i in range(len(note_classes))]\n",
    "\n",
    "def replace_char(prediction, i, new_char):\n",
    "    return prediction[:i] + new_char + prediction[i+1:]\n",
    "\n",
    "hold_lengths = [3, 6, 9, 12, 18, 24, 36, 48]\n",
    "pattern = ['1000', '0100', '0001', '0010', '0100', '1000', '0001', '0010', '1000', '0100', '0001', '0010', '0100', '1000', '0001', '0010']\n",
    "cutoff_per_class = [0, 0.88, 0.96, 1, 0.98, 1, 0.98]\n",
    "def get_output(note_classes):\n",
    "    hold_lengths_current = [0, 0, 0, 0]\n",
    "    roll_lengths_current = [0, 0, 0, 0]\n",
    "    hold_lengths_max = [12, 12, 12, 12]\n",
    "    roll_lengths_max = [12, 12, 12, 12]\n",
    "    predicted_notes = []\n",
    "    # TODO: figure out better normilazation\n",
    "    normalized_note_classes = normalize_classes(note_classes)\n",
    "    sortedLists = [sorted(normalized_note_classes, key=itemgetter(i)) for i in range(7)]\n",
    "    num_samples = len(note_classes)\n",
    "    cutoffs = [sortedLists[i][min(int(num_samples * cutoff_per_class[i]), len(sortedLists[i]) - 1)][i] for i in range(7)]\n",
    "    \n",
    "    note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * song_padding), note_classes, ([[1, 0, 0, 0, 0, 0, 0]] * song_end_padding)), axis = 0)\n",
    "    dummy_rows = [row for eigth in pattern for row in [eigth] + ['0000'] * 5]\n",
    "    features = [get_features_for_row(row) for row in dummy_rows]\n",
    "    for i in range(num_samples):\n",
    "        note_class = note_classes[i]\n",
    "        normalized_note_class = normalized_note_classes[i]\n",
    "        prediction = '0000'\n",
    "        X_row = get_features(len(features) - song_padding, features, note_classes)\n",
    "        # order by reverse importance of decision\n",
    "        # TODO up limit if something has been bumped out of existance (eg put more jumps if they get covered by holds)\n",
    "        targets = ['0', '1', '1', '1', '2', '4', 'M']\n",
    "        ammounts = [0, 1, 2, 3, 1, 1, 1]\n",
    "        for i in [1, 6, 2, 5, 4, 3]:\n",
    "            if normalized_note_class[i] > cutoffs[i]:\n",
    "                prediction_values = note_models[i].predict(np.array([X_row]))[0]\n",
    "                prediction_values = [value + random.uniform(-0.01, 0.01) for value in prediction_values]\n",
    "                number_to_include = ammounts[i]\n",
    "                for j in range(4):\n",
    "                    if hold_lengths_current[j] > 0 or roll_lengths_current[j] > 0:\n",
    "                        number_to_include -= 1\n",
    "                cutoff = sorted(prediction_values)[-(max(0, number_to_include) + 1)]\n",
    "                prediction = ''.join([targets[i] if value > cutoff else '0' for value in prediction_values])\n",
    "        \n",
    "        for i in range(4):\n",
    "            if hold_lengths_current[i] > 0:\n",
    "                hold_lengths_current[i] += 1\n",
    "                if hold_lengths_current[i] == hold_lengths_max[i]:\n",
    "                    prediction = replace_char(prediction, i, '3')\n",
    "                    hold_lengths_current[i] = 0\n",
    "                else:\n",
    "                    prediction = replace_char(prediction, i, '0')\n",
    "            if roll_lengths_current[i] > 0:\n",
    "                roll_lengths_current[i] += 1\n",
    "                if roll_length_currents[i] == roll_lengths_max[i]:\n",
    "                    prediction = replace_char(prediction, i, '3')\n",
    "                    roll_lengths_current[i] = 0\n",
    "                else:\n",
    "                    prediction = replace_char(prediction, i, '0')\n",
    "            if prediction[i] == '2':\n",
    "                hold_lengths_index = np.argmax(hold_length_model.predict(np.array([X_row]))[0])\n",
    "                hold_lengths_current[i] = 1\n",
    "                hold_lengths_max[i] = hold_lengths[hold_lengths_index]\n",
    "            if prediction[i] == '4':\n",
    "                roll_lengths_index = np.argmax(roll_length_model.predict(np.array([X_row]))[0])\n",
    "                roll_lengths_current[i] = 1\n",
    "                roll_lengths_max[i] = hold_lengths[roll_lengths_index]\n",
    "\n",
    "        predicted_notes.append(prediction)\n",
    "        features.append(get_features_for_row(prediction))\n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_song_metadata(output_stepfile, song, music_file, offset, bpm):\n",
    "    keys = ['TITLE', 'MUSIC', 'OFFSET', 'SAMPLESTART', 'SAMPLELENGTH', 'SELECTABLE', 'BPMS']\n",
    "    header_info = {\n",
    "        'TITLE': song,\n",
    "        'MUSIC': music_file,\n",
    "        'OFFSET': -offset,\n",
    "        'SAMPLESTART': offset + 32 * (60. / bpm),\n",
    "        'SAMPLELENGTH': 32 * (60. / bpm),\n",
    "        'SELECTABLE': 'YES',\n",
    "        'BPMS': '0.000={:.3f}'.format(bpm)\n",
    "    }\n",
    "    \n",
    "    for key in keys:\n",
    "        print (\"#{0}:{1};\".format(key, str(header_info[key])), file=output_stepfile)\n",
    "        \n",
    "def write_song_steps(output_stepfile, predicted_notes):\n",
    "    print(\"\\n//---------------dance-single - J. Zukewich----------------\", file=output_stepfile)\n",
    "    print (\"#NOTES:\", file=output_stepfile)\n",
    "    for detail in ['dance-single', 'J. Zukewich', 'Expert', '9', '0.242,0.312,0.204,0.000,0.000']:\n",
    "        print ('\\t{0}:'.format(detail), file=output_stepfile)\n",
    "    \n",
    "    for i in range(len(predicted_notes)):\n",
    "        row = predicted_notes[i]\n",
    "        if i == len(predicted_notes) - 1:\n",
    "            row += ';'\n",
    "        print (row, file=output_stepfile)\n",
    "        if i % steps_per_bar == steps_per_bar - 1 and i != len(predicted_notes) - 1:\n",
    "            print (\",\", file=output_stepfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "song_class_model = load_model('models/song_class_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "note_models = [None] + [load_model('models/note_model_{0}.h5'.format(i)) for i in range(1, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_length_model = load_model('models/hold_length_model.h5')\n",
    "roll_length_model = load_model('models/roll_length_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOS\n",
    "- Figure out ending\n",
    "- cap complexity limit (no 1 purple)\n",
    "- get predicted ammounts of holds etc for song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind Saved Features for Delirium\n",
      "Getting Song Predicted Classes\n",
      "Predicting Notes\n",
      "Writing Song to File\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "music_file = 'Delirium.ogg'\n",
    "regenerate_features = False\n",
    "regenerate_note_classes = True\n",
    "regenerate_notes = True\n",
    "step_song(music_file, regenerate_features, regenerate_note_classes, regenerate_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind Saved Features for View\n",
      "Getting Song Predicted Classes\n",
      "Predicting Notes\n",
      "Writing Song to File\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "music_file = 'View.mp3'\n",
    "regenerate_features = False\n",
    "regenerate_note_classes = True\n",
    "regenerate_notes = True\n",
    "step_song(music_file, regenerate_features, regenerate_note_classes, regenerate_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind Saved Features for Fire\n",
      "Getting Song Predicted Classes\n",
      "Predicting Notes\n",
      "Writing Song to File\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "music_file = 'Fire.mp3'\n",
    "regenerate_features = False\n",
    "regenerate_note_classes = True\n",
    "regenerate_notes = True\n",
    "step_song(music_file, regenerate_features, regenerate_note_classes, regenerate_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step_song(music_file, regenerate_features, regenerate_note_classes, regenerate_notes):\n",
    "    song, _ = music_file.split('.')\n",
    "    key = song\n",
    "    folder = 'StepMania/Songs/a_Generated/{0}/'.format(song)\n",
    "    stepfile_name = '{0}.sm'.format(song)\n",
    "    saved_data = listdir('prod_data')\n",
    "    if not exists(folder):\n",
    "        makedirs(folder)\n",
    "    copyfile('to_step/' + music_file, folder + music_file)\n",
    "\n",
    "    if not regenerate_features and ('{0}_beat_features.csv'.format(key) in saved_data and '{0}_misc.csv'.format(key) in saved_data):\n",
    "        print ('Loadind Saved Features for {0}'.format(song))\n",
    "        [offset], [bpm] = pd.read_csv('prod_data/{0}_misc.csv'.format(key)).values\n",
    "        beat_features = pd.read_csv('prod_data/{0}_beat_features.csv'.format(key)).values\n",
    "    else:\n",
    "        print ('Loading Song {0}'.format(song))\n",
    "        y, _ = librosa.load('to_step/' + music_file, sr=sr)\n",
    "\n",
    "        print ('Calculating BPM')\n",
    "        offset, bpm = load_misc_from_music(y)\n",
    "        pd.DataFrame([offset, bpm]).to_csv('prod_data/{0}_misc.csv'.format(key), index=False)\n",
    "\n",
    "        print ('Calculating Features')\n",
    "        indices = calculate_indices(offset, bpm, y)\n",
    "        beat_features = calculate_features(indices, y)\n",
    "        pd.DataFrame(beat_features).to_csv('prod_data/{0}_beat_features.csv'.format(key), index=False)\n",
    "    y = None\n",
    "    indices = None\n",
    "\n",
    "    if not regenerate_note_classes and ('{0}_note_classes_generated.csv'.format(key) in saved_data):\n",
    "        print ('Loading Song Predicted Classes')\n",
    "        note_classes = pd.read_csv('prod_data/{0}_note_classes_generated.csv'.format(key)).values\n",
    "    else:\n",
    "        print ('Getting Song Predicted Classes')\n",
    "        X = get_features_for_song(beat_features)\n",
    "        note_classes = song_class_model.predict(X)\n",
    "        pd.DataFrame(note_classes).to_csv('prod_data/{0}_note_classes_generated.csv'.format(key), index=False)\n",
    "    beat_features = None\n",
    "    X = None\n",
    "\n",
    "    if not regenerate_notes and ('{0}_predicted_notes.csv'.format(key) in saved_data):\n",
    "        print ('Loading Predicted Notes')\n",
    "        predicted_notes = pd.read_csv('prod_data/{0}_predicted_notes.csv'.format(key)).values\n",
    "    else:\n",
    "        print ('Predicting Notes')\n",
    "        predicted_notes = get_output(note_classes)\n",
    "        pd.DataFrame(predicted_notes).to_csv('prod_data/{0}_predicted_notes.csv'.format(key), index=False)\n",
    "    note_classes = None\n",
    "\n",
    "    print ('Writing Song to File')\n",
    "    stepfile=open(folder + stepfile_name, 'w')\n",
    "    write_song_metadata(stepfile, song, music_file, offset, bpm)\n",
    "    write_song_steps(stepfile, predicted_notes)\n",
    "    stepfile.close()\n",
    "\n",
    "    print ('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "music_file = 'CallMeBaby.mp3'\n",
    "regenerate_features = False\n",
    "regenerate_note_classes = True\n",
    "regenerate_notes = True\n",
    "step_song(music_file, regenerate_features, regenerate_note_classes, regenerate_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
