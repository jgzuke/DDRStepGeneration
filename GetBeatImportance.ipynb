{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note types\n",
    "- 0: nothing\n",
    "- 1: step\n",
    "- 2: hold start\n",
    "- 3: hold/roll end\n",
    "- 4: roll start\n",
    "- M: mine\n",
    "\n",
    "# Classes\n",
    "- 0: nothing\n",
    "- 1: one note\n",
    "- 2: two notes\n",
    "- 3: three or four notes\n",
    "- 4: hold start\n",
    "- 5: roll start\n",
    "- 6: mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 8\n",
    "num_classes = 7\n",
    "num_features = 40\n",
    "num_features_total = (num_features * samples_back_included) + 4\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, notes, index):\n",
    "    if index < 0:\n",
    "        return [0] * num_features\n",
    "    return beat_features[index]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    if index < 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    row = notes[index][0]\n",
    "    (steps, holds, rolls, mines) = [row.count(char) for char in ['1', '2', '4', 'M']]\n",
    "    steps += (holds + rolls)\n",
    "    return [int(i) for i in [steps == 0 and mines == 0, steps == 1, steps == 2, steps > 2, holds > 0, rolls > 0, mines > 0]]\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(key, is_full):\n",
    "    X = []\n",
    "    y = []\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        num_notes = min(len(notes), len(beat_features))\n",
    "        for i in range(num_notes):\n",
    "            row_y = get_class_for_index(notes, i)\n",
    "            if is_full or (not (row_y == 0 and random.randint(0, 5) != 0)):\n",
    "                features = [feature for j in range(samples_back_included) for feature in get_features_for_index(beat_features, notes, i - j)]\n",
    "                features.append(i % 48)\n",
    "                features.append(get_beat_importance(i))\n",
    "                features.append(i / 48)\n",
    "                features.append(num_notes - i / 48)\n",
    "                X.append(features)\n",
    "                y.append(row_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Total 243 songs\n",
    "def build_training_data(songs_start, songs_end, is_full = False):\n",
    "    X = []\n",
    "    y = []\n",
    "    songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "    for song_data in songs_to_use[songs_start:songs_end]:\n",
    "        song_X, song_y = get_features_for_song(song_data[0], is_full)\n",
    "        X.extend(song_X)\n",
    "        y.extend(song_y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start with each input secion maps to one note\n",
    "# train model for that (just list comprhension on noets for contains 1 maps to true)\n",
    "\n",
    "# then move to bars eg section of 4 bars maps to output for each note\n",
    "# error = probability of note being true vs was it really\n",
    "\n",
    "# try bar + prev notes (home use weird dimensioned data?) to predict next notes\n",
    "\n",
    "# try feeding in non structured data (bpm, position of time in song, song length, \n",
    "# things about feel of song (generated features))\n",
    "# try using keras merge layer to add extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = build_training_data(0, 243, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: 2,\n",
    "    2: 4,\n",
    "    3: 8,\n",
    "    4: 4,\n",
    "    5: 4,\n",
    "    6: 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beat_feature_model = Sequential()\n",
    "\n",
    "beat_feature_model.add(Dense(500, input_dim=num_features_total, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.5))\n",
    "\n",
    "beat_feature_model.add(Dense(500, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.5))\n",
    "\n",
    "beat_feature_model.add(Dense(500, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.5))\n",
    "\n",
    "beat_feature_model.add(Dense(num_classes, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('softmax'))\n",
    "\n",
    "beat_feature_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adadelta',\n",
    "                           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "601265/601265 [==============================] - 29176s - loss: 0.5004 - acc: 0.8506 \n",
      "Epoch 2/5\n",
      "601265/601265 [==============================] - 2191s - loss: 0.4688 - acc: 0.8557  \n",
      "Epoch 3/5\n",
      "601265/601265 [==============================] - 2007s - loss: 0.4661 - acc: 0.8564  \n",
      "Epoch 4/5\n",
      "601265/601265 [==============================] - 2012s - loss: 0.4650 - acc: 0.8569  \n",
      "Epoch 5/5\n",
      "601265/601265 [==============================] - 2014s - loss: 0.4647 - acc: 0.8570  \n"
     ]
    }
   ],
   "source": [
    "beat_feature_model.fit(np.array(X_train), np.array(y_train), nb_epoch=5, batch_size=5) #, class_weight=class_weight)\n",
    "beat_feature_model.save('models/beat_importance_model_classes_full_testing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beat_feature_model = Sequential()\n",
    "# 5186, 8482\n",
    "beat_feature_model.add(Dense(500, input_dim=num_features_total, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.5))\n",
    "\n",
    "beat_feature_model.add(Dense(500, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.5))\n",
    "\n",
    "beat_feature_model.add(Dense(500, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.5))\n",
    "\n",
    "beat_feature_model.add(Dense(num_classes, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('softmax'))\n",
    "\n",
    "beat_feature_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adadelta',\n",
    "                           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "601265/601265 [==============================] - 2046s - loss: 0.9665 - acc: 0.8285  \n",
      "Epoch 2/5\n",
      "601265/601265 [==============================] - 1932s - loss: 0.9158 - acc: 0.8232  \n",
      "Epoch 3/5\n",
      "601265/601265 [==============================] - 1961s - loss: 0.9128 - acc: 0.8250  \n",
      "Epoch 4/5\n",
      "601265/601265 [==============================] - 1894s - loss: 0.9109 - acc: 0.8270  \n",
      "Epoch 5/5\n",
      "601265/601265 [==============================] - 1940s - loss: 0.9086 - acc: 0.8281  \n"
     ]
    }
   ],
   "source": [
    "beat_feature_model.fit(np.array(X_train), np.array(y_train), nb_epoch=5, batch_size=5, class_weight=class_weight)\n",
    "beat_feature_model.save('models/beat_importance_model_classes_full_testing_with_classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_song(key, clf):\n",
    "    song_X, song_y = get_features_for_song(key, True)\n",
    "    new_song_y = clf.predict(song_X)\n",
    "    \n",
    "    pd.DataFrame(new_song_y).to_csv('generated_data/{0}_note_classes_generated.csv'.format(key), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beat_feature_model = load_model('models/beat_importance_model_classes_full_testing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error loading song\n",
      "In The Groove~I Think I Like That Sound\n",
      "\n",
      "Error loading song\n",
      "In The Groove~Remember December\n",
      "\n",
      "Error loading song\n",
      "In The Groove~Torn\n",
      "\n",
      "Error loading song\n",
      "In The Groove~Walking on Fire\n",
      "\n",
      "Error loading song\n",
      "In The Groove 2~!\n",
      "\n",
      "Error loading song\n",
      "In The Groove 2~Fleadh Uncut\n",
      "\n",
      "Error loading song\n",
      "In The Groove 2~Hardcore Symphony\n",
      "\n",
      "Error loading song\n",
      "In The Groove 2~Holy Guacamole\n",
      "\n",
      "Error loading song\n",
      "In The Groove 2~Reactor\n",
      "\n",
      "Error loading song\n",
      "In The Groove 3~DJ Superstar\n",
      "\n",
      "Error loading song\n",
      "In The Groove 3~Land of Imagination\n",
      "\n",
      "Error loading song\n",
      "In The Groove 3~Online\n",
      "\n",
      "Error loading song\n",
      "In The Groove 3~Partyman\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth~Space Space Shooter\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth +~Roppongi Carillon\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Death From Above\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Elder God Shrine\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~La Samba de la Vida\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Night Flight to Tokyo\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Ninja Boy\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Style on my Speed Dial\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Team Rocket\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Tike Tike Kardi\n",
      "\n",
      "Error loading song\n",
      "In The Groove Rebirth 2 (BETA)~Toy Soldiers\n",
      "\n",
      "Error loading song\n",
      "Piece of Cake 2~(-[Jayce]-) - Divine Olivine - [10]\n",
      "\n",
      "Error loading song\n",
      "Piece of Cake 5~(-[Jayce]-) - I Run NY - [09]\n"
     ]
    }
   ],
   "source": [
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "failed_song_keys = []\n",
    "for song_data in songs_to_use:\n",
    "    try:\n",
    "        step_song(song_data[0], beat_feature_model)\n",
    "    except:\n",
    "        print ('\\nError loading song')\n",
    "        print (song_data[0])\n",
    "        failed_song_keys.append(song_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "failed_song_keys = ['In The Groove~I Think I Like That Sound',\n",
    " 'In The Groove~Remember December',\n",
    " 'In The Groove~Torn',\n",
    " 'In The Groove~Walking on Fire',\n",
    " 'In The Groove 2~!',\n",
    " 'In The Groove 2~Fleadh Uncut',\n",
    " 'In The Groove 2~Hardcore Symphony',\n",
    " 'In The Groove 2~Holy Guacamole',\n",
    " 'In The Groove 2~Reactor',\n",
    " 'In The Groove 3~DJ Superstar',\n",
    " 'In The Groove 3~Land of Imagination',\n",
    " 'In The Groove 3~Online',\n",
    " 'In The Groove 3~Partyman',\n",
    " 'In The Groove Rebirth~Space Space Shooter',\n",
    " 'In The Groove Rebirth +~Roppongi Carillon',\n",
    " 'In The Groove Rebirth 2 (BETA)~Death From Above',\n",
    " 'In The Groove Rebirth 2 (BETA)~Elder God Shrine',\n",
    " 'In The Groove Rebirth 2 (BETA)~La Samba de la Vida',\n",
    " 'In The Groove Rebirth 2 (BETA)~Night Flight to Tokyo',\n",
    " 'In The Groove Rebirth 2 (BETA)~Ninja Boy',\n",
    " 'In The Groove Rebirth 2 (BETA)~Style on my Speed Dial',\n",
    " 'In The Groove Rebirth 2 (BETA)~Team Rocket',\n",
    " 'In The Groove Rebirth 2 (BETA)~Tike Tike Kardi',\n",
    " 'In The Groove Rebirth 2 (BETA)~Toy Soldiers',\n",
    " 'Piece of Cake 2~(-[Jayce]-) - Divine Olivine - [10]',\n",
    " 'Piece of Cake 5~(-[Jayce]-) - I Run NY - [09]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
