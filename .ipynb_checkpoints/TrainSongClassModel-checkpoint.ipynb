{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import gc\n",
    "from os import listdir\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n"
     ]
    }
   ],
   "source": [
    "%alias_magic t timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note types\n",
    "- 0: nothing\n",
    "- 1: step\n",
    "- 2: hold start\n",
    "- 3: hold/roll end\n",
    "- 4: roll start\n",
    "- M: mine\n",
    "\n",
    "# Classes\n",
    "- 0: nothing\n",
    "- 1: one note\n",
    "- 2: two notes\n",
    "- 3: three or four notes\n",
    "- 4: hold start\n",
    "- 5: roll start\n",
    "- 6: mine\n",
    "\n",
    "# Remember\n",
    "clf = joblib.load('filename.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 8\n",
    "num_classes = 7\n",
    "num_features = 40\n",
    "num_features_total = (num_features * samples_back_included) + 4\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, notes, index):\n",
    "    if index < 0:\n",
    "        return [0] * num_features\n",
    "    return beat_features[index]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    if index < 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    row = notes[index][0]\n",
    "    (steps, holds, rolls, mines) = [row.count(char) for char in ['1', '2', '4', 'M']]\n",
    "    steps += (holds + rolls)\n",
    "    return [int(i) for i in [steps == 0 and mines == 0, steps == 1, steps == 2, steps > 2, holds > 0, rolls > 0, mines > 0]]\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_features_for_song(key, is_full):\n",
    "    X = []\n",
    "    y = []\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        num_notes = min(len(notes), len(beat_features))\n",
    "        for i in range(num_notes):\n",
    "            row_y = get_class_for_index(notes, i)\n",
    "            if is_full or (not (row_y == 0 and random.randint(0, 5) != 0)):\n",
    "                features = [feature for j in range(samples_back_included) for feature in get_features_for_index(beat_features, notes, i - j)]\n",
    "                features.append(i % 48)\n",
    "                features.append(get_beat_importance(i))\n",
    "                features.append(i / 48)\n",
    "                features.append(num_notes - i / 48)\n",
    "                X.append(features)\n",
    "                y.append(row_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Total 243 songs\n",
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "def build_training_data(is_full, start, end):\n",
    "    X = []\n",
    "    y = []\n",
    "    songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "    for song_data in songs_to_use[start:end]:\n",
    "        song_X, song_y = get_features_for_song(song_data[0], is_full)\n",
    "        X.extend(song_X)\n",
    "        y.extend(song_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = build_training_data(True, 0, 194)\n",
    "y_train = np.array(list(map(lambda one_hot: np.argmax(one_hot), y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = build_training_data(True, 194, 243)\n",
    "y_test = np.array(list(map(lambda one_hot: np.argmax(one_hot), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=0, learning_rate=0.12, n_estimators=25, max_depth=7, subsample=0.85, max_features=200, verbose=True)\n",
    "gb_clf.fit(X_train[:100000], y_train[:100000])\n",
    "print (gb_clf.score(X_train[:100000], y_train[:100000]))\n",
    "print (gb_clf.score(X_test, y_test))\n",
    "joblib.dump(gb_clf, 'gb_clf1.pkl')\n",
    "gc.collect()\n",
    "# 0.891653430684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       77317.0745        3012.9254           48.89m\n",
      "         2       64503.8453        2125.2472           49.59m\n",
      "         3       54740.1825        1621.9064           49.25m\n",
      "         4       46966.5138        1249.8163           49.24m\n",
      "         5       40731.9701         993.5149           47.87m\n",
      "         6       35804.0404         790.2325           45.72m\n",
      "         7       31545.0480         642.4337           43.98m\n",
      "         8       28232.2055         502.3321           42.17m\n",
      "         9       25536.8471         414.1295           39.81m\n",
      "        10       22930.9312         338.0288           37.60m\n",
      "        20       11501.9519          54.8783           12.57m\n",
      "0.97099\n",
      "0.864501730052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=0, learning_rate=0.12, n_estimators=25, max_depth=10, subsample=0.85, max_features=200, verbose=True)\n",
    "gb_clf.fit(X_train[:100000], y_train[:100000])\n",
    "print (gb_clf.score(X_train[:100000], y_train[:100000]))\n",
    "print (gb_clf.score(X_test, y_test))\n",
    "joblib.dump(gb_clf, 'gb_clf2.pkl')\n",
    "gc.collect()\n",
    "#0.97099\n",
    "#0.864501730052"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1       73806.7067        3027.5629          204.83m\n",
      "         2       59173.8587        2107.8607          266.74m\n",
      "         3       48155.8397        1594.7845          304.16m\n",
      "         4       39490.5831        1236.5233          320.75m\n",
      "         5       32628.4095         995.1022          324.76m\n",
      "         6       27022.2342         796.0695          325.48m\n",
      "         7       22424.2507         638.3685          334.62m\n",
      "         8       18690.6681         512.6263          335.57m\n",
      "         9       15627.6145         423.7054          329.96m\n",
      "        10       13047.0904         340.6485          321.32m\n",
      "        20        2505.5305          47.9474          113.01m\n",
      "1.0\n",
      "0.870732912928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(random_state=0, learning_rate=0.12, n_estimators=25, max_depth=20, subsample=0.85, max_features=200, verbose=True)\n",
    "gb_clf.fit(X_train[:100000], y_train[:100000])\n",
    "print (gb_clf.score(X_train[:100000], y_train[:100000]))\n",
    "print (gb_clf.score(X_test, y_test))\n",
    "joblib.dump(gb_clf, 'gb_clf3.pkl')\n",
    "gc.collect()\n",
    "#1.0\n",
    "#0.870732912928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed: 15.9min finished\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87673941373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "169"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 25, max_features=200, min_samples_leaf=4, verbose=True)\n",
    "rf_clf.fit(X_train[:100000], y_train[:100000])\n",
    "print (rf_clf.score(X_train[:100000], y_train[:100000]))\n",
    "print (rf_clf.score(X_test, y_test))\n",
    "joblib.dump(rf_clf, 'rf_clf_final.pkl')\n",
    "gc.collect()\n",
    "# 0.900850706427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 100, max_features=200, min_samples_leaf=12, verbose=True)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "print (rf_clf.score(X_train, y_train))\n",
    "print (rf_clf.score(X_test, y_test))\n",
    "joblib.dump(rf_clf, 'rf_clf_final.pkl')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.885299268107\n",
      "0.881996974281\n",
      "CPU times: user 1h 55min 59s, sys: 33.4 s, total: 1h 56min 33s\n",
      "Wall time: 31min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf = XGBClassifier(max_depth = 3, min_child_weight=8, learning_rate=0.05, seed=0, n_estimators=100, subsample=0.80, colsample_bytree=0.80, objective=\"multi:softprob\")\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "print (accuracy_score(y_train, xgb_clf.predict(X_train)))\n",
    "print (accuracy_score(y_test, xgb_clf.predict(X_test)))\n",
    "joblib.dump(xgb_clf, 'xgb_clf.pkl')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_clf = XGBClassifier(max_depth = 4, min_child_weight=8, learning_rate=0.05, seed=0, n_estimators=100, subsample=0.80, colsample_bytree=0.80, objective=\"multi:softprob\")\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "print (accuracy_score(y_train, xgb_clf.predict(X_train)))\n",
    "print (accuracy_score(y_test, xgb_clf.predict(X_test)))\n",
    "joblib.dump(xgb_clf, 'xgb_clf.pkl')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(loss=\"log\", verbose=True)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "print (sgd_clf.score(X_train, y_train))\n",
    "print (sgd_clf.score(X_test, y_test))\n",
    "joblib.dump(gb_clf, 'rf_clf6.pkl')\n",
    "gc.collect()\n",
    "# 0.849 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(324,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, nb_epoch=50, batch_size=64, verbose=1)\n",
    "print (model.evaluate(X_test, y_test_2, batch_size=64))\n",
    "model.save('models/song_class_model.h5')\n",
    "model = None\n",
    "gc.collect()\n",
    "# 0.88877616359785194 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
