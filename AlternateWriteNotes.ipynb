{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output of song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_song_header(output_stepfile, song):\n",
    "    keys = ['TITLE', 'MUSIC', 'OFFSET', 'SAMPLESTART', 'SAMPLELENGTH', 'SELECTABLE', 'BPMS']\n",
    "    header_info = {\n",
    "        'TITLE': song.name,\n",
    "        'MUSIC': '{0}.{1}'.format(song.name, song.extension),\n",
    "        'OFFSET': -song.offset,\n",
    "        'SAMPLESTART': song.offset + 32 * song.beat_length,\n",
    "        'SAMPLELENGTH': 32 * song.beat_length,\n",
    "        'SELECTABLE': 'YES',\n",
    "        'BPMS': '0.000={:.3f}'.format(song.bpm)\n",
    "    }\n",
    "    \n",
    "    for key in keys:\n",
    "        print (\"#{0}:{1};\".format(key, str(header_info[key])), file=output_stepfile)\n",
    "        \n",
    "def write_step_header(output_stepfile, song):\n",
    "    print(\"\\n//---------------dance-single - J. Zukewich----------------\", file=output_stepfile)\n",
    "    print (\"#NOTES:\", file=output_stepfile)\n",
    "    for detail in ['dance-single', 'J. Zukewich', 'Expert', '9', '0.242,0.312,0.204,0.000,0.000']:\n",
    "        print ('\\t{0}:'.format(detail), file=output_stepfile)\n",
    "    \n",
    "    for i in range(len(song.predicted_notes)):\n",
    "        row = song.predicted_notes[i]\n",
    "        print (row, file=output_stepfile)\n",
    "        if i % steps_per_bar == steps_per_bar - 1:\n",
    "            print (\",\", file=output_stepfile)\n",
    "\n",
    "    print (\"0000;\", file=output_stepfile)\n",
    "    \n",
    "def step_song(song):\n",
    "    if song.name + '.sm' in os.listdir(song.folder) and not song.name + '.sm.backup' in os.listdir(song.folder):\n",
    "        os.rename(song.stepfile_name, song.stepfile_name + '.backup')\n",
    "            \n",
    "    output_stepfile=open(song.stepfile_name, 'w')\n",
    "    write_song_header(output_stepfile, song)\n",
    "    write_step_header(output_stepfile, song)\n",
    "    output_stepfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instead of training models for each note\n",
    "- decide which will have notes, for now pick x with one, y with another (train model for this + holds, hands, mines, rolls etc later)\n",
    "- for each note that will have something, decide what combo it has (train from prev notes (not all 48, pick more relevant ones)) (4 for one note, 6 for 2, 4 for 3) and pick highest class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS\n",
    "- try to predict hold/roll there (would need to train on later beat info as well)\n",
    "- generate percent of single double notes etc with a nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_bar = 48\n",
    "class SongFile:\n",
    "    def __init__(self, key, folder, stepfile, music_file):\n",
    "        misc = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "        self.note_classes = pd.read_csv('generated_data/{0}_note_classes_generated.csv'.format(key), converters={'0': lambda x: float(x)}).values\n",
    "        self.notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        self.folder = folder\n",
    "        self.name = key.split('~')[1]\n",
    "        self.music_name = music_file\n",
    "        self.stepfile_name = stepfile\n",
    "        self.offset = misc[0][0]\n",
    "        self.beat_length = 60. / misc[1][0]\n",
    "        self.bpm = misc[1][0]\n",
    "        self.extension = music_file.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "save_files = listdir('data')\n",
    "save_files_generated = listdir('generated_data')\n",
    "songs = {}\n",
    "for song_data in songs_to_use:\n",
    "    key = song_data[0]\n",
    "    if '{0}_misc.csv'.format(key) in save_files and '{0}_note_classes_generated.csv'.format(key) in save_files_generated:\n",
    "        songs[key] = SongFile(key, song_data[1], song_data[2], song_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beats_to_track = 48\n",
    "num_classes_one_note = 4\n",
    "num_classes_two_note = 6\n",
    "class_map_one_note = {\n",
    "    '1000': 0,\n",
    "    '0100': 1,\n",
    "    '0010': 2,\n",
    "    '0001': 3\n",
    "}\n",
    "class_reverse_map_one_note = ['1000', '0100', '0010', '0001']\n",
    "\n",
    "class_map_two_note = {\n",
    "    '1001': 0,\n",
    "    '0110': 1,\n",
    "    '1100': 2,\n",
    "    '1010': 3,\n",
    "    '0101': 4,\n",
    "    '0011': 5\n",
    "}\n",
    "class_reverse_map_two_note = ['1001', '0110', '1100', '1010', '0101', '0011']\n",
    "\n",
    "note_types = ['0', '1', 'M', '2', '4', '3']\n",
    "\n",
    "def get_features_for_row(row):\n",
    "    return [int(char == target) for target in note_types for char in row]\n",
    "\n",
    "song_padding = beats_to_track * 2\n",
    "song_end_padding = beats_to_track * 2\n",
    "important_indices = [1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "important_indices_classes = [-96, -84, -72, -60, -48, -36, -24, -12, 0, 1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "def get_features(index, features, note_classes):\n",
    "    indices = [index + song_padding - i for i in important_indices]\n",
    "    indices_classes = [index + song_padding - i for i in important_indices_classes]\n",
    "    return np.concatenate((np.array([note_classes[i] for i in indices_classes]).flatten(), np.array([features[i] for i in indices]).flatten()), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(100, input_dim=776, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(500, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(500, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_classes, init='uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                               optimizer='adadelta',\n",
    "                               metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes\n",
    "- 1: one note\n",
    "- 2: two notes\n",
    "- 3: three or four notes\n",
    "- 4: hold start\n",
    "- 5: roll start\n",
    "- 6: mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_class_for_notes(row):\n",
    "    note_counts = [row.count(note_type) for note_type in note_types]\n",
    "    (blank, steps, mines, hold_starts, roll_starts, hold_ends) = note_counts\n",
    "    \n",
    "    model_classes = []\n",
    "    if steps + hold_starts + roll_starts == 1:\n",
    "        model_classes.append(1)\n",
    "\n",
    "    if steps + hold_starts + roll_starts == 2:\n",
    "        model_classes.append(2)\n",
    "        \n",
    "    if steps + hold_starts + roll_starts > 2:\n",
    "        model_classes.append(3)\n",
    "        \n",
    "    if hold_starts > 0:\n",
    "        model_classes.append(4)\n",
    "        \n",
    "    if roll_starts > 0:\n",
    "        model_classes.append(5)\n",
    "        \n",
    "    if mines > 0:\n",
    "        model_classes.append(6)\n",
    "        \n",
    "    return model_classes\n",
    "\n",
    "targets = ['0', '1', '1', '1', '2', '4', 'M']\n",
    "ammounts = [0, 1, 2, 3, 1, 1, 1]\n",
    "def get_model_output_for_class(model_class, row):\n",
    "    if model_class == 1 or model_class == 2 or model_class == 3:\n",
    "        return [int(char == '1' or char == '2' or char == '4') for char in row]\n",
    "    if model_class == 4:\n",
    "        return [int(char == '2') for char in row]\n",
    "    if model_class == 5:\n",
    "        return [int(char == '4') for char in row]\n",
    "    if model_class == 6:\n",
    "        return [int(char == 'M') for char in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [[] for i in range(7)]\n",
    "y = [[] for i in range(7)]\n",
    "for key in list(songs.keys()):\n",
    "    note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * song_padding), songs[key].note_classes, ([[1, 0, 0, 0, 0, 0, 0]] * song_end_padding)), axis = 0)\n",
    "    notes = np.concatenate((([['0000']] * song_padding), songs[key].notes), axis = 0)\n",
    "    if abs(len(note_classes) - len(notes) > 250):\n",
    "        print ('Lengths dont match for {0}'.format(key))\n",
    "        print ('{0} vs {1}'.format(len(note_classes), len(notes)))\n",
    "        continue\n",
    "    length = min(len(note_classes) - song_padding - song_end_padding, len(notes) - song_padding)\n",
    "    features = np.array([get_features_for_row(notes[i][0]) for i in range(-song_padding, length)])\n",
    "    for i in range(length):\n",
    "        row = notes[i + song_padding][0]\n",
    "        model_classes = get_model_class_for_notes(row)\n",
    "        for model_class in model_classes:\n",
    "            X[model_class].append(get_features(i, features, note_classes))\n",
    "            y[model_class].append(get_model_output_for_class(model_class, row))\n",
    "\n",
    "X = [np.array(X_for_class) for X_for_class in X]\n",
    "y = [np.array(y_for_class) for y_for_class in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 82708, 6598, 36, 6484, 228, 3985]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(X[i]) for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "82708/82708 [==============================] - 114s - loss: 1.3873 - acc: 0.2706   \n",
      "Epoch 2/3\n",
      "82708/82708 [==============================] - 108s - loss: 1.3810 - acc: 0.2760   \n",
      "Epoch 3/3\n",
      "82708/82708 [==============================] - 96s - loss: 1.3808 - acc: 0.2750    \n",
      "Epoch 1/3\n",
      "6598/6598 [==============================] - 61s - loss: 2.7705 - acc: 0.1954    \n",
      "Epoch 2/3\n",
      "6598/6598 [==============================] - 67s - loss: 2.7707 - acc: 0.1593    \n",
      "Epoch 3/3\n",
      "6598/6598 [==============================] - 70s - loss: 2.7709 - acc: 0.2149    \n",
      "Epoch 1/3\n",
      "36/36 [==============================] - 0s - loss: 4.5057 - acc: 0.0000e+00     \n",
      "Epoch 2/3\n",
      "36/36 [==============================] - 0s - loss: 4.5054 - acc: 0.0000e+00     \n",
      "Epoch 3/3\n",
      "36/36 [==============================] - 0s - loss: 4.5052 - acc: 0.0000e+00     \n",
      "Epoch 1/3\n",
      "6484/6484 [==============================] - 72s - loss: 1.4875 - acc: 0.2483    \n",
      "Epoch 2/3\n",
      "6484/6484 [==============================] - 73s - loss: 1.4874 - acc: 0.2523    \n",
      "Epoch 3/3\n",
      "6484/6484 [==============================] - 64s - loss: 1.4874 - acc: 0.2469    \n",
      "Epoch 1/3\n",
      "228/228 [==============================] - 1s - loss: 1.4657 - acc: 0.2193     \n",
      "Epoch 2/3\n",
      "228/228 [==============================] - 1s - loss: 1.4656 - acc: 0.2105     \n",
      "Epoch 3/3\n",
      "228/228 [==============================] - 1s - loss: 1.4656 - acc: 0.2105     \n",
      "Epoch 1/3\n",
      "3985/3985 [==============================] - 34s - loss: 1.9707 - acc: 0.2675    \n",
      "Epoch 2/3\n",
      "3985/3985 [==============================] - 32s - loss: 1.9707 - acc: 0.2700    \n",
      "Epoch 3/3\n",
      "3985/3985 [==============================] - 32s - loss: 1.9707 - acc: 0.2878    \n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(None)\n",
    "for i in range(1, 7):\n",
    "    model = build_model(4)\n",
    "    model.fit(X[i], y[i], nb_epoch=3, batch_size=math.ceil(len(X[i]) / 10000))\n",
    "    model.save('models/write_notes_model_{0}.h5'.format(i))\n",
    "    models.append(model)\n",
    "# Dense 1000: 63s - loss: 1.3934 - acc: 0.2707\n",
    "# Dense 550: 53s - loss: 1.3903 - acc: 0.2703\n",
    "# Dense 100: 30s - loss: 1.3950 - acc: 0.2699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_average_for_class(note_classes, i, class_num):\n",
    "    surrounding_beats = note_classes[max(i - 24,0):min(i + 24,len(note_classes))]\n",
    "    return sum([beat[class_num] for beat in surrounding_beats]) / float(len(surrounding_beats))\n",
    "\n",
    "def normalize_row(note_classes, i):\n",
    "    return [note_classes[i][class_num] - get_average_for_class(note_classes, i, class_num) for class_num in range(7)]\n",
    "    \n",
    "def normalize_classes(note_classes):\n",
    "    return [normalize_row(note_classes, i) for i in range(len(note_classes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = ['1000', '0100', '0001', '0010', '0100', '1000', '0001', '0010', '1000', '0100', '0001', '0010', '0100', '1000', '0001', '0010']\n",
    "cutoff_per_class = [0, 0.9, 0.97, 0.99, 0.99, 0.99, 0.99]\n",
    "def get_output(song):\n",
    "    predicted_notes = []\n",
    "    normalized_note_classes = song.note_classes #normalize_classes(song.note_classes)\n",
    "    sortedLists = [sorted(normalized_note_classes, key=itemgetter(i)) for i in range(7)]\n",
    "    num_samples = len(song.note_classes)\n",
    "    cutoffs = [sortedLists[i][int(num_samples * cutoff_per_class[i])][i] for i in range(7)]\n",
    "    \n",
    "    note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * song_padding), song.note_classes, ([[1, 0, 0, 0, 0, 0, 0]] * song_end_padding)), axis = 0)\n",
    "    dummy_rows = [row for eigth in pattern for row in [eigth] + ['0000'] * 5]\n",
    "    features = [get_features_for_row(row) for row in dummy_rows]\n",
    "    for i in range(num_samples):\n",
    "        note_class = song.note_classes[i]\n",
    "        normalized_note_class = normalized_note_classes[i]\n",
    "        prediction = '0000'\n",
    "        for i in range(1, 7):\n",
    "            if normalized_note_class[i] > cutoffs[i]:\n",
    "                X_row = get_features(len(features) - song_padding, features, note_classes)\n",
    "                prediction_values = models[i].predict(np.array([X_row]))[0]\n",
    "                cutoff = sorted(prediction_values)[-ammounts[i]]\n",
    "                prediction = ''.join([targets[i] if value >= cutoff else '0' for value in prediction_values])\n",
    "\n",
    "        predicted_notes.append(prediction)\n",
    "        features.append(get_features_for_row(prediction))\n",
    "    return predicted_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step_song_by_name(name):\n",
    "    song = songs['In The Groove~{0}'.format(name)]\n",
    "    song.predicted_notes = get_output(song)\n",
    "    step_song(song)\n",
    "\n",
    "step_song_by_name('Anubis')\n",
    "step_song_by_name('Bend Your Mind')\n",
    "step_song_by_name('Boogie Down')\n",
    "step_song_by_name('Bouff')\n",
    "step_song_by_name('Bubble Dancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_notes = []\n",
    "normalized_note_classes = song.note_classes\n",
    "sortedLists = [sorted(normalized_note_classes, key=itemgetter(i)) for i in range(7)]\n",
    "num_samples = len(song.note_classes)\n",
    "cutoffs = [sortedLists[i][int(num_samples * cutoff_per_class[i])][i] for i in range(7)]\n",
    "\n",
    "note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * song_padding), song.note_classes, ([[1, 0, 0, 0, 0, 0, 0]] * song_end_padding)), axis = 0)\n",
    "dummy_rows = [row for eigth in pattern for row in [eigth] + ['0000'] * 5]\n",
    "features = [get_features_for_row(row) for row in dummy_rows]\n",
    "for i in range(num_samples):\n",
    "    note_class = song.note_classes[i]\n",
    "    normalized_note_class = normalized_note_classes[i]\n",
    "    prediction = '0000'\n",
    "    for i in range(1, 7):\n",
    "        if normalized_note_class[i] > cutoffs[i]:\n",
    "            X_row = get_features(len(features) - song_padding, features, note_classes)\n",
    "            prediction_values = models[i].predict(np.array([X_row]))[0]\n",
    "            cutoff = sorted(prediction_values)[-ammounts[i]]\n",
    "            prediction = ''.join([targets[i] if value >= cutoff else '0' for value in prediction_values])\n",
    "\n",
    "    predicted_notes.append(prediction)\n",
    "    features.append(get_features_for_row(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15125609934329987,\n",
       " 0.57552510499954224,\n",
       " 0.11418217420578004,\n",
       " 9.7502605058252798e-05,\n",
       " 0.091162502765655531,\n",
       " 0.00068649463355541218,\n",
       " 0.033921748399734497]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
