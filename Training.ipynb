{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class SongFile:\n",
    "    def __init__(self, key, folder, stepfile, music_file):\n",
    "        misc = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "        raw_notes = pd.read_csv('data/{0}_notes_generated.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        notes = [row[0] for row in raw_notes]\n",
    "        self.folder = folder\n",
    "        self.name = key.split('~')[1]\n",
    "        self.music_name = music_file\n",
    "        self.stepfile_name = stepfile\n",
    "        self.offset = misc[0][0]\n",
    "        self.beat_length = 60. / misc[1][0]\n",
    "        self.bpm = misc[1][0]\n",
    "        self.notes = notes\n",
    "        self.extension = music_file.split('.')[1]\n",
    "\n",
    "def write_song_header(output_stepfile, song):\n",
    "    keys = ['TITLE', 'MUSIC', 'OFFSET', 'SAMPLESTART', 'SAMPLELENGTH', 'SELECTABLE', 'BPMS']\n",
    "    header_info = {\n",
    "        'TITLE': song.name,\n",
    "        'MUSIC': '{0}.{1}'.format(song.name, song.extension),\n",
    "        'OFFSET': -song.offset,\n",
    "        'SAMPLESTART': song.offset + 32 * song.beat_length,\n",
    "        'SAMPLELENGTH': 32 * song.beat_length,\n",
    "        'SELECTABLE': 'YES',\n",
    "        'BPMS': '0.000={:.3f}'.format(song.bpm)\n",
    "    }\n",
    "    \n",
    "    for key in keys:\n",
    "        print (\"#{0}:{1};\".format(key, str(header_info[key])), file=output_stepfile)\n",
    "        \n",
    "def write_step_header(output_stepfile, song):\n",
    "    print(\"\\n//---------------dance-single - J. Zukewich----------------\", file=output_stepfile)\n",
    "    print (\"#NOTES:\", file=output_stepfile)\n",
    "    for detail in ['dance-single', 'J. Zukewich', 'Expert', '9', '0.242,0.312,0.204,0.000,0.000']:\n",
    "        print ('\\t{0}:'.format(detail), file=output_stepfile)\n",
    "    \n",
    "    for i in range(len(song.notes)):\n",
    "        row = song.notes[i]\n",
    "        print (row, file=output_stepfile)\n",
    "        if i % 48 == 48 - 1:\n",
    "            print (\",\", file=output_stepfile)\n",
    "\n",
    "    print (\"0000;\", file=output_stepfile)\n",
    "    \n",
    "def write_song_steps(song):\n",
    "    if song.name + '.sm' in os.listdir(song.folder) and not song.name + '.sm.backup' in os.listdir(song.folder):\n",
    "        os.rename(song.stepfile_name, song.stepfile_name + '.backup')\n",
    "            \n",
    "    output_stepfile=open(song.stepfile_name, 'w')\n",
    "    write_song_header(output_stepfile, song)\n",
    "    write_step_header(output_stepfile, song)\n",
    "    output_stepfile.close()\n",
    "\n",
    "def write_song_steps_by_key(key):\n",
    "    pack, song = key.split('~')\n",
    "    folder = 'StepMania/Songs/{0}/{1}/'.format(pack, song)\n",
    "    stepfile = folder + '/{0}.sm'.format(song)\n",
    "    music = folder + [file for file in listdir(folder) if file.endswith('.ogg') or file.endswith('.mp3')][0]\n",
    "\n",
    "    write_song_steps(SongFile(key, folder, stepfile, music))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_back_included = 8\n",
    "num_classes = 5\n",
    "num_features = 40 + 2\n",
    "num_features_total = (num_features * samples_back_included) + 3\n",
    "save_files = listdir('data')\n",
    "\n",
    "def get_features_for_index(beat_features, notes, index):\n",
    "    if index < 0:\n",
    "        return [0] * num_features\n",
    "    return np.concatenate((beat_features[index], get_steps_for_index(notes, index - 1)))\n",
    "\n",
    "def get_steps_for_index(notes, index):\n",
    "    if index < 0:\n",
    "        return (0, 0)\n",
    "    row = notes[index][0]\n",
    "    return [row.count('1'), row.count('M')]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    steps, mines = get_steps_for_index(notes, index)\n",
    "    if mines > 0:\n",
    "        return 4\n",
    "    return min(steps, 3)\n",
    "    \n",
    "importance_rankings = [48, 24, 12, 16, 6, 8, 3, 4, 2, 1]\n",
    "def get_beat_importance(index):\n",
    "    for i in range(len(importance_rankings)):\n",
    "        if index % importance_rankings[i] == 0:\n",
    "            return i\n",
    "\n",
    "def get_full_features_for_song(key):\n",
    "    X = []\n",
    "    y = []\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        for i in range(min(len(notes), len(beat_features))):\n",
    "            features = [feature for j in range(samples_back_included) for feature in get_features_for_index(beat_features, notes, i - (j*3))]\n",
    "            features.append(i % 48)\n",
    "            features.append(get_beat_importance(i))\n",
    "            features.append(i / 48)\n",
    "            X.append(features)\n",
    "            y.append(get_class_for_index(notes, i))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_features_for_song(key):\n",
    "    X = []\n",
    "    y = []\n",
    "    if '{0}_beat_features.csv'.format(key) in save_files and '{0}_notes.csv'.format(key) in save_files:\n",
    "        beat_features_rotated = pd.read_csv('data/{0}_beat_features.csv'.format(key)).values\n",
    "        notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        beat_features = np.flipud(np.rot90(np.array(beat_features_rotated)))\n",
    "        for i in range(min(len(notes), len(beat_features))):\n",
    "            row_y = get_class_for_index(notes, i)\n",
    "            if not (row_y == 0 and random.randint(0, 35) != 0) and not (row_y == 1 and random.randint(0, 5) != 0):\n",
    "                features = [feature for j in range(samples_back_included) for feature in get_features_for_index(beat_features, notes, i - j)]\n",
    "                features.append(i % 48)\n",
    "                features.append(get_beat_importance(i))\n",
    "                features.append(i / 48)\n",
    "                X.append(features)\n",
    "                y.append(row_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_batch_generator():\n",
    "    songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "    for song_data in songs_to_use:\n",
    "        yield (get_features_for_song(song_data[0]))\n",
    "\n",
    "# Total 243 songs\n",
    "def build_training_data(songs_start, songs_end):\n",
    "    X = []\n",
    "    y = []\n",
    "    songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "    for song_data in songs_to_use[songs_start:songs_end]:\n",
    "        song_X, song_y = get_features_for_song(song_data[0])\n",
    "        X.extend(song_X)\n",
    "        y.extend(song_y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = ['0000', '1000', '1100', '1111', 'MMMM']\n",
    "def prediction_to_output_class(row):\n",
    "    return outputs[row]\n",
    "\n",
    "def prediction_to_output_one_hot(row):\n",
    "    return outputs[np.argmax(row)]\n",
    "\n",
    "def step_song(key, clf, prediction_to_output):\n",
    "    song_X, song_y = get_full_features_for_song(key)\n",
    "    new_song_y = clf.predict(song_X)\n",
    "    new_song_output = [prediction_to_output(row) for row in new_song_y]\n",
    "    \n",
    "    #print ('Length: ' + str(len(new_song_y)))\n",
    "    #plt.plot([new_song_y[i] for i in range(len(new_song_y)) if i % 12 == 0])\n",
    "    #plt.show()\n",
    "    \n",
    "    pd.DataFrame(new_song_output).to_csv('data/{0}_notes_generated.csv'.format(key), index=False)\n",
    "    write_song_steps_by_key(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start with each input secion maps to one note\n",
    "# train model for that (just list comprhension on noets for contains 1 maps to true)\n",
    "\n",
    "# then move to bars eg section of 4 bars maps to output for each note\n",
    "# error = probability of note being true vs was it really\n",
    "\n",
    "# try bar + prev notes (home use weird dimensioned data?) to predict next notes\n",
    "\n",
    "# try feeding in non structured data (bpm, position of time in song, song length, \n",
    "# things about feel of song (generated features))\n",
    "# try using keras merge layer to add extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = build_training_data(0, 200)\n",
    "X_test, y_test = build_training_data(200, 243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=20)\n",
    "clf_rf.fit(X, y)\n",
    "\n",
    "#for song in ['Anubis', 'Bend Your Mind', 'Boogie Down', 'Bouff', 'Bubble Dancer']:\n",
    "#    step_song('In The Groove~{0}'.format(song), clf_rf, prediction_to_output_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beat_feature_model = Sequential()\n",
    "\n",
    "beat_feature_model.add(Dense(500, input_dim=num_features_total, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.3))\n",
    "\n",
    "beat_feature_model.add(Dense(500, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('tanh'))\n",
    "beat_feature_model.add(Dropout(0.3))\n",
    "\n",
    "beat_feature_model.add(Dense(num_classes, init='uniform'))\n",
    "beat_feature_model.add(BatchNormalization())\n",
    "beat_feature_model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "beat_feature_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adadelta',\n",
    "                           metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30502/30502 [==============================] - 9s - loss: 1.3691 - acc: 0.4702     \n",
      "Epoch 2/10\n",
      "30502/30502 [==============================] - 9s - loss: 1.0791 - acc: 0.6196     \n",
      "Epoch 3/10\n",
      "30502/30502 [==============================] - 9s - loss: 0.9944 - acc: 0.6397     \n",
      "Epoch 4/10\n",
      "30502/30502 [==============================] - 11s - loss: 0.9482 - acc: 0.6488    \n",
      "Epoch 5/10\n",
      "30502/30502 [==============================] - 11s - loss: 0.9120 - acc: 0.6539    \n",
      "Epoch 6/10\n",
      "30502/30502 [==============================] - 9s - loss: 0.8908 - acc: 0.6582     \n",
      "Epoch 7/10\n",
      "30502/30502 [==============================] - 10s - loss: 0.8716 - acc: 0.6639    \n",
      "Epoch 8/10\n",
      "30502/30502 [==============================] - 10s - loss: 0.8561 - acc: 0.6664    \n",
      "Epoch 9/10\n",
      "30502/30502 [==============================] - 10s - loss: 0.8397 - acc: 0.6724    \n",
      "Epoch 10/10\n",
      "30502/30502 [==============================] - 10s - loss: 0.8318 - acc: 0.6744    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b9a5b38>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = np.zeros((len(y_train), num_classes))\n",
    "y_one_hot[np.arange(len(y_train)), y_train] = 1\n",
    "\n",
    "beat_feature_model.fit(np.array(X_train), y_one_hot, nb_epoch=10, batch_size=64) #, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136/3138 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.92511076703810102, 0.63001912045889097]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_one_hot = np.zeros((len(y_test), num_classes))\n",
    "y_one_hot[np.arange(len(y_test)), y_test] = 1\n",
    "\n",
    "beat_feature_model.evaluate(np.array(X_test), y_one_hot, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "step_song('In The Groove~Anubis', beat_feature_model, prediction_to_output_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
