{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instead of training models for each note\n",
    "- decide which will have notes, for now pick x with one, y with another (train model for this + holds, hands, mines, rolls etc later)\n",
    "- for each note that will have something, decide what combo it has (train from prev notes (not all 48, pick more relevant ones)) (4 for one note, 6 for 2, 4 for 3) and pick highest class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS\n",
    "- try to predict hold/roll there (would need to train on later beat info as well)\n",
    "- generate percent of single double notes etc with a nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "- 1: one note\n",
    "- 2: two notes\n",
    "- 3: three or four notes\n",
    "- 4: hold start\n",
    "- 5: roll start\n",
    "- 6: mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_bar = 48\n",
    "class SongFile:\n",
    "    def __init__(self, key, folder, stepfile, music_file):\n",
    "        misc = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "        self.note_classes = pd.read_csv('generated_data/{0}_note_classes_generated.csv'.format(key), converters={'0': lambda x: float(x)}).values\n",
    "        self.notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        self.folder = folder\n",
    "        self.name = key.split('~')[1]\n",
    "        self.music_name = music_file\n",
    "        self.stepfile_name = stepfile\n",
    "        self.offset = misc[0][0]\n",
    "        self.beat_length = 60. / misc[1][0]\n",
    "        self.bpm = misc[1][0]\n",
    "        self.extension = music_file.split('.')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "songs_to_use = pd.read_csv('data/songs_to_use.csv').values\n",
    "save_files = listdir('data')\n",
    "save_files_generated = listdir('generated_data')\n",
    "songs = {}\n",
    "for song_data in songs_to_use:\n",
    "    key = song_data[0]\n",
    "    if '{0}_misc.csv'.format(key) in save_files and '{0}_note_classes_generated.csv'.format(key) in save_files_generated:\n",
    "        songs[key] = SongFile(key, song_data[1], song_data[2], song_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beats_to_track = 48\n",
    "num_classes_one_note = 4\n",
    "num_classes_two_note = 6\n",
    "class_map_one_note = {\n",
    "    '1000': 0,\n",
    "    '0100': 1,\n",
    "    '0010': 2,\n",
    "    '0001': 3\n",
    "}\n",
    "class_reverse_map_one_note = ['1000', '0100', '0010', '0001']\n",
    "\n",
    "class_map_two_note = {\n",
    "    '1001': 0,\n",
    "    '0110': 1,\n",
    "    '1100': 2,\n",
    "    '1010': 3,\n",
    "    '0101': 4,\n",
    "    '0011': 5\n",
    "}\n",
    "class_reverse_map_two_note = ['1001', '0110', '1100', '1010', '0101', '0011']\n",
    "\n",
    "note_types = ['0', '1', 'M', '2', '4', '3']\n",
    "\n",
    "def get_features_for_row(row):\n",
    "    return [int(char == target) for target in note_types for char in row]\n",
    "\n",
    "empty_row = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "def get_previous_notes(index, features):\n",
    "    previous_notes = [features[i] for i in range(index, index + song_padding) if not np.array_equal(features[i], empty_row)]\n",
    "    return [empty_row] * (8 - len(previous_notes)) + previous_notes[-8:]\n",
    "    \n",
    "song_padding = beats_to_track * 2\n",
    "song_end_padding = beats_to_track * 2\n",
    "important_indices = [1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "important_indices_classes = [-96, -84, -72, -60, -48, -36, -24, -12, 0, 1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "def get_features(index, features, note_classes):\n",
    "    indices = [index + song_padding - i for i in important_indices]\n",
    "    indices_classes = [index + song_padding - i for i in important_indices_classes]\n",
    "    past_classes = np.array([note_classes[i] for i in indices_classes]).flatten()\n",
    "    past_features = np.array([features[i] for i in indices]).flatten()\n",
    "    previous_notes = np.array(get_previous_notes(index, features)).flatten()\n",
    "    return np.concatenate((past_classes, past_features, previous_notes), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_class_for_notes(row):\n",
    "    note_counts = [row.count(note_type) for note_type in note_types]\n",
    "    (blank, steps, mines, hold_starts, roll_starts, hold_ends) = note_counts\n",
    "    \n",
    "    model_classes = []\n",
    "    if steps + hold_starts + roll_starts == 1:\n",
    "        model_classes.append(1)\n",
    "\n",
    "    if steps + hold_starts + roll_starts == 2:\n",
    "        model_classes.append(2)\n",
    "        \n",
    "    if steps + hold_starts + roll_starts > 2:\n",
    "        model_classes.append(3)\n",
    "        \n",
    "    if hold_starts > 0:\n",
    "        model_classes.append(4)\n",
    "        \n",
    "    if roll_starts > 0:\n",
    "        model_classes.append(5)\n",
    "        \n",
    "    if mines > 0:\n",
    "        model_classes.append(6)\n",
    "        \n",
    "    return model_classes\n",
    "\n",
    "def get_model_output_for_class(model_class, row):\n",
    "    if model_class == 1 or model_class == 2 or model_class == 3:\n",
    "        return [int(char == '1' or char == '2' or char == '4') for char in row]\n",
    "    if model_class == 4:\n",
    "        return [int(char == '2') for char in row]\n",
    "    if model_class == 5:\n",
    "        return [int(char == '4') for char in row]\n",
    "    if model_class == 6:\n",
    "        return [int(char == 'M') for char in row]\n",
    "\n",
    "def get_hold_length(notes, note_row, note_column):\n",
    "    i = 0\n",
    "    while i < len(notes) - note_row:\n",
    "        if notes[note_row + i][0][note_column] == '3':\n",
    "            return i\n",
    "        i += 1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hold_X = []\n",
    "roll_X = []\n",
    "hold_y = []\n",
    "roll_y = []\n",
    "X = [[] for i in range(7)]\n",
    "y = [[] for i in range(7)]\n",
    "for key in list(songs.keys()):\n",
    "    note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * song_padding), songs[key].note_classes, ([[1, 0, 0, 0, 0, 0, 0]] * song_end_padding)), axis = 0)\n",
    "    notes = np.concatenate((([['0000']] * song_padding), songs[key].notes), axis = 0)\n",
    "    if abs(len(note_classes) - len(notes) > 250):\n",
    "        print ('Lengths dont match for {0}'.format(key))\n",
    "        print ('{0} vs {1}'.format(len(note_classes), len(notes)))\n",
    "        continue\n",
    "    length = min(len(note_classes) - song_padding - song_end_padding, len(notes) - song_padding)\n",
    "    features = np.array([get_features_for_row(notes[i][0]) for i in range(0, length + song_padding)])\n",
    "    for i in range(length):\n",
    "        row = notes[i + song_padding][0]\n",
    "        model_classes = get_model_class_for_notes(row)\n",
    "        for model_class in model_classes:\n",
    "            X_row = get_features(i, features, note_classes)\n",
    "            X[model_class].append(X_row)\n",
    "            y[model_class].append(get_model_output_for_class(model_class, row))\n",
    "            if model_class == 4:\n",
    "                for j in range(4):\n",
    "                    if row[j] == '2':\n",
    "                        length = get_hold_length(notes, i + song_padding, j)\n",
    "                        if length:\n",
    "                            hold_X.append(X_row)\n",
    "                            hold_y.append(length)\n",
    "            if model_class == 5:\n",
    "                for j in range(4):\n",
    "                    if row[j] == '4':\n",
    "                        length = get_hold_length(notes, i + song_padding, j)\n",
    "                        if length:\n",
    "                            roll_X.append(X_row)\n",
    "                            roll_y.append(length)\n",
    "\n",
    "X = [np.array(X_for_class) for X_for_class in X]\n",
    "y = [np.array(y_for_class) for y_for_class in y]\n",
    "hold_X = np.array(hold_X)\n",
    "roll_X = np.array(roll_X)\n",
    "for i in range(1,7):\n",
    "    X[i], y[i] = shuffle(X[i], y[i], random_state=0)\n",
    "hold_X, hold_y = shuffle(hold_X, hold_y, random_state=0)\n",
    "roll_X, roll_y = shuffle(roll_X, roll_y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_lengths = [3, 6, 9, 12, 18, 24, 36, 48]\n",
    "def get_closest_hold_lengths(lengths):\n",
    "    closest = [np.argmax([-abs(length - aprox) for aprox in hold_lengths]) for length in lengths]\n",
    "    closest_one_hot = np.zeros((len(closest), len(hold_lengths)))\n",
    "    closest_one_hot[np.arange(len(closest)), closest] = 1\n",
    "    return np.array(closest_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5487 samples, validate on 1372 samples\n",
      "Epoch 1/2\n",
      "5487/5487 [==============================] - 5s - loss: 1.7789 - acc: 0.3845 - val_loss: 2.0513 - val_acc: 0.2770\n",
      "Epoch 2/2\n",
      "5487/5487 [==============================] - 4s - loss: 1.3003 - acc: 0.5847 - val_loss: 1.7163 - val_acc: 0.4125\n"
     ]
    }
   ],
   "source": [
    "hold_y_transformed = get_closest_hold_lengths(hold_y)\n",
    "X_hold_train, X_hold_test, y_hold_train, y_hold_test = train_test_split(hold_X, hold_y_transformed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roll_y_transformed = get_closest_hold_lengths(roll_y)\n",
    "X_roll_train, X_roll_test, y_roll_train, y_roll_test = train_test_split(roll_X, roll_y_transformed, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5487 samples, validate on 1372 samples\n",
      "Epoch 1/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.8947 - acc: 0.3231 - val_loss: 1.9650 - val_acc: 0.3120\n",
      "Epoch 2/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.5705 - acc: 0.4680 - val_loss: 1.7886 - val_acc: 0.3972\n",
      "Epoch 3/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.4374 - acc: 0.5181 - val_loss: 1.6230 - val_acc: 0.4687\n",
      "Epoch 4/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.3349 - acc: 0.5688 - val_loss: 1.4928 - val_acc: 0.5153\n",
      "Epoch 5/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.2626 - acc: 0.5925 - val_loss: 1.4669 - val_acc: 0.5270\n",
      "Epoch 6/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.1842 - acc: 0.6337 - val_loss: 1.4217 - val_acc: 0.5270\n",
      "Epoch 7/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.1184 - acc: 0.6586 - val_loss: 1.4141 - val_acc: 0.5299\n",
      "Epoch 8/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.0618 - acc: 0.6803 - val_loss: 1.3943 - val_acc: 0.5415\n",
      "Epoch 9/20\n",
      "5487/5487 [==============================] - 1s - loss: 1.0330 - acc: 0.6871 - val_loss: 1.3869 - val_acc: 0.5386\n",
      "Epoch 10/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.9893 - acc: 0.7017 - val_loss: 1.4052 - val_acc: 0.5292\n",
      "Epoch 11/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.9519 - acc: 0.7197 - val_loss: 1.3962 - val_acc: 0.5255\n",
      "Epoch 12/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.9146 - acc: 0.7315 - val_loss: 1.3797 - val_acc: 0.5474\n",
      "Epoch 13/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.8840 - acc: 0.7403 - val_loss: 1.3771 - val_acc: 0.5350\n",
      "Epoch 14/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.8472 - acc: 0.7560 - val_loss: 1.3745 - val_acc: 0.5379\n",
      "Epoch 15/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.8180 - acc: 0.7676 - val_loss: 1.3727 - val_acc: 0.5394\n",
      "Epoch 16/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.7932 - acc: 0.7780 - val_loss: 1.3678 - val_acc: 0.5481\n",
      "Epoch 17/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.7766 - acc: 0.7828 - val_loss: 1.3518 - val_acc: 0.5532\n",
      "Epoch 18/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.7537 - acc: 0.7879 - val_loss: 1.3677 - val_acc: 0.5474\n",
      "Epoch 19/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.7417 - acc: 0.7953 - val_loss: 1.3543 - val_acc: 0.5561\n",
      "Epoch 20/20\n",
      "5487/5487 [==============================] - 1s - loss: 0.7161 - acc: 0.8086 - val_loss: 1.3519 - val_acc: 0.5517\n"
     ]
    }
   ],
   "source": [
    "hold_model = Sequential()\n",
    "\n",
    "hold_model.add(Dense(512, input_shape=(968,)))\n",
    "hold_model.add(BatchNormalization())\n",
    "hold_model.add(Activation('relu'))\n",
    "hold_model.add(Dropout(0.5))\n",
    "\n",
    "hold_model.add(Dense(512))\n",
    "hold_model.add(BatchNormalization())\n",
    "hold_model.add(Activation('relu'))\n",
    "hold_model.add(Dropout(0.5))\n",
    "\n",
    "hold_model.add(Dense(len(hold_lengths)))\n",
    "hold_model.add(BatchNormalization())\n",
    "hold_model.add(Activation('softmax'))\n",
    "\n",
    "hold_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hold_model.fit(X_hold_train, y_hold_train, nb_epoch=20, batch_size=64, verbose=1, validation_data=(X_hold_test, y_hold_test))\n",
    "hold_model.save('models/hold_length_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 189 samples, validate on 48 samples\n",
      "Epoch 1/20\n",
      "189/189 [==============================] - 0s - loss: 2.1933 - acc: 0.1958 - val_loss: 1.8109 - val_acc: 0.3333\n",
      "Epoch 2/20\n",
      "189/189 [==============================] - 0s - loss: 1.2344 - acc: 0.6190 - val_loss: 1.8288 - val_acc: 0.3125\n",
      "Epoch 3/20\n",
      "189/189 [==============================] - 0s - loss: 0.9441 - acc: 0.8095 - val_loss: 1.8253 - val_acc: 0.3542\n",
      "Epoch 4/20\n",
      "189/189 [==============================] - 0s - loss: 0.8070 - acc: 0.8942 - val_loss: 1.8261 - val_acc: 0.3958\n",
      "Epoch 5/20\n",
      "189/189 [==============================] - 0s - loss: 0.7634 - acc: 0.9259 - val_loss: 1.8525 - val_acc: 0.3750\n",
      "Epoch 6/20\n",
      "189/189 [==============================] - 0s - loss: 0.7093 - acc: 0.9312 - val_loss: 1.8715 - val_acc: 0.3958\n",
      "Epoch 7/20\n",
      "189/189 [==============================] - 0s - loss: 0.6410 - acc: 0.9735 - val_loss: 1.8690 - val_acc: 0.3750\n",
      "Epoch 8/20\n",
      "189/189 [==============================] - 0s - loss: 0.6263 - acc: 0.9577 - val_loss: 1.8499 - val_acc: 0.3958\n",
      "Epoch 9/20\n",
      "189/189 [==============================] - 0s - loss: 0.5873 - acc: 0.9841 - val_loss: 1.8382 - val_acc: 0.3750\n",
      "Epoch 10/20\n",
      "189/189 [==============================] - 0s - loss: 0.5421 - acc: 0.9947 - val_loss: 1.8442 - val_acc: 0.3542\n",
      "Epoch 11/20\n",
      "189/189 [==============================] - 0s - loss: 0.5366 - acc: 0.9947 - val_loss: 1.8476 - val_acc: 0.3542\n",
      "Epoch 12/20\n",
      "189/189 [==============================] - 0s - loss: 0.5512 - acc: 0.9841 - val_loss: 1.8570 - val_acc: 0.3333\n",
      "Epoch 13/20\n",
      "189/189 [==============================] - 0s - loss: 0.5111 - acc: 0.9947 - val_loss: 1.8460 - val_acc: 0.3542\n",
      "Epoch 14/20\n",
      "189/189 [==============================] - 0s - loss: 0.4958 - acc: 0.9947 - val_loss: 1.8548 - val_acc: 0.3542\n",
      "Epoch 15/20\n",
      "189/189 [==============================] - 0s - loss: 0.4875 - acc: 0.9947 - val_loss: 1.8480 - val_acc: 0.3750\n",
      "Epoch 16/20\n",
      "189/189 [==============================] - 0s - loss: 0.4998 - acc: 0.9894 - val_loss: 1.8684 - val_acc: 0.3125\n",
      "Epoch 17/20\n",
      "189/189 [==============================] - 0s - loss: 0.5078 - acc: 0.9841 - val_loss: 1.8496 - val_acc: 0.3542\n",
      "Epoch 18/20\n",
      "189/189 [==============================] - 0s - loss: 0.4669 - acc: 1.0000 - val_loss: 1.8398 - val_acc: 0.3333\n",
      "Epoch 19/20\n",
      "189/189 [==============================] - 0s - loss: 0.4598 - acc: 0.9947 - val_loss: 1.8315 - val_acc: 0.3333\n",
      "Epoch 20/20\n",
      "189/189 [==============================] - 0s - loss: 0.4470 - acc: 0.9947 - val_loss: 1.8387 - val_acc: 0.3333\n"
     ]
    }
   ],
   "source": [
    "roll_model = Sequential()\n",
    "\n",
    "roll_model.add(Dense(512, input_shape=(968,)))\n",
    "roll_model.add(BatchNormalization())\n",
    "roll_model.add(Activation('relu'))\n",
    "roll_model.add(Dropout(0.5))\n",
    "\n",
    "roll_model.add(Dense(512))\n",
    "roll_model.add(BatchNormalization())\n",
    "roll_model.add(Activation('relu'))\n",
    "roll_model.add(Dropout(0.5))\n",
    "\n",
    "roll_model.add(Dense(len(hold_lengths)))\n",
    "roll_model.add(BatchNormalization())\n",
    "roll_model.add(Activation('softmax'))\n",
    "\n",
    "roll_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "roll_model.fit(X_roll_train, y_roll_train, nb_epoch=20, batch_size=64, verbose=1, validation_data=(X_roll_test, y_roll_test))\n",
    "roll_model.save('models/roll_length_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, input_shape=(968,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adagrad',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 66166 samples, validate on 16542 samples\n",
      "Epoch 1/10\n",
      "66166/66166 [==============================] - 52s - loss: 1.1968 - acc: 0.4240 - val_loss: 1.1680 - val_acc: 0.4379\n",
      "Epoch 2/10\n",
      "66166/66166 [==============================] - 50s - loss: 1.1235 - acc: 0.4738 - val_loss: 1.1559 - val_acc: 0.4518\n",
      "Epoch 3/10\n",
      "66166/66166 [==============================] - 48s - loss: 1.0790 - acc: 0.5048 - val_loss: 1.1545 - val_acc: 0.4525\n",
      "Epoch 4/10\n",
      "66166/66166 [==============================] - 43s - loss: 1.0361 - acc: 0.5329 - val_loss: 1.1586 - val_acc: 0.4565\n",
      "Epoch 5/10\n",
      "66166/66166 [==============================] - 43s - loss: 0.9926 - acc: 0.5613 - val_loss: 1.1837 - val_acc: 0.4411\n",
      "Epoch 6/10\n",
      "66166/66166 [==============================] - 50s - loss: 0.9468 - acc: 0.5881 - val_loss: 1.1874 - val_acc: 0.4547\n",
      "Epoch 7/10\n",
      "66166/66166 [==============================] - 62s - loss: 0.9106 - acc: 0.6092 - val_loss: 1.1893 - val_acc: 0.4590\n",
      "Epoch 8/10\n",
      "66166/66166 [==============================] - 60s - loss: 0.8733 - acc: 0.6304 - val_loss: 1.1973 - val_acc: 0.4587\n",
      "Epoch 9/10\n",
      "66166/66166 [==============================] - 59s - loss: 0.8386 - acc: 0.6504 - val_loss: 1.2084 - val_acc: 0.4580\n",
      "Epoch 10/10\n",
      "66166/66166 [==============================] - 65s - loss: 0.8105 - acc: 0.6670 - val_loss: 1.2245 - val_acc: 0.4541\n",
      "Train on 5278 samples, validate on 1320 samples\n",
      "Epoch 1/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.8203 - acc: 0.2914 - val_loss: 2.7501 - val_acc: 0.2000\n",
      "Epoch 2/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.6583 - acc: 0.3484 - val_loss: 2.7444 - val_acc: 0.2333\n",
      "Epoch 3/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.5563 - acc: 0.3806 - val_loss: 2.7517 - val_acc: 0.2311\n",
      "Epoch 4/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.4138 - acc: 0.4079 - val_loss: 2.8001 - val_acc: 0.2780\n",
      "Epoch 5/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.2755 - acc: 0.4528 - val_loss: 2.8942 - val_acc: 0.2803\n",
      "Epoch 6/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.1572 - acc: 0.4655 - val_loss: 2.9556 - val_acc: 0.3553\n",
      "Epoch 7/10\n",
      "5278/5278 [==============================] - 5s - loss: 2.0829 - acc: 0.4716 - val_loss: 3.0038 - val_acc: 0.2977\n",
      "Epoch 8/10\n",
      "5278/5278 [==============================] - 4s - loss: 2.0291 - acc: 0.4843 - val_loss: 2.9945 - val_acc: 0.2902\n",
      "Epoch 9/10\n",
      "5278/5278 [==============================] - 4s - loss: 1.9787 - acc: 0.4767 - val_loss: 3.2003 - val_acc: 0.3871\n",
      "Epoch 10/10\n",
      "5278/5278 [==============================] - 5s - loss: 1.9375 - acc: 0.4930 - val_loss: 3.0404 - val_acc: 0.2591\n",
      "Train on 28 samples, validate on 8 samples\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s - loss: 5.7946 - acc: 0.1429 - val_loss: 5.6992 - val_acc: 0.2500\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s - loss: 4.5067 - acc: 0.3214 - val_loss: 5.3385 - val_acc: 0.3750\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s - loss: 4.1358 - acc: 0.3929 - val_loss: 4.9657 - val_acc: 0.3750\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s - loss: 4.0897 - acc: 0.2500 - val_loss: 5.0127 - val_acc: 0.3750\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s - loss: 4.0648 - acc: 0.3571 - val_loss: 4.8375 - val_acc: 0.3750\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s - loss: 4.0573 - acc: 0.5357 - val_loss: 4.7644 - val_acc: 0.3750\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s - loss: 4.0538 - acc: 0.2143 - val_loss: 4.7112 - val_acc: 0.3750\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s - loss: 4.0424 - acc: 0.4643 - val_loss: 4.7199 - val_acc: 0.3750\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s - loss: 4.0310 - acc: 0.2857 - val_loss: 4.6954 - val_acc: 0.3750\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s - loss: 4.0368 - acc: 0.1429 - val_loss: 4.6413 - val_acc: 0.3750\n",
      "Train on 5187 samples, validate on 1297 samples\n",
      "Epoch 1/10\n",
      "5187/5187 [==============================] - 5s - loss: 1.4445 - acc: 0.3626 - val_loss: 1.3898 - val_acc: 0.3863\n",
      "Epoch 2/10\n",
      "5187/5187 [==============================] - 5s - loss: 1.1777 - acc: 0.5360 - val_loss: 1.4126 - val_acc: 0.3454\n",
      "Epoch 3/10\n",
      "5187/5187 [==============================] - 5s - loss: 0.9679 - acc: 0.6537 - val_loss: 1.3881 - val_acc: 0.3847\n",
      "Epoch 4/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.7946 - acc: 0.7640 - val_loss: 1.4903 - val_acc: 0.3801\n",
      "Epoch 5/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.6690 - acc: 0.8379 - val_loss: 1.4456 - val_acc: 0.3894\n",
      "Epoch 6/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.5784 - acc: 0.8839 - val_loss: 1.6064 - val_acc: 0.3901\n",
      "Epoch 7/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.5474 - acc: 0.9017 - val_loss: 1.5041 - val_acc: 0.3863\n",
      "Epoch 8/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.4869 - acc: 0.9279 - val_loss: 1.4666 - val_acc: 0.4148\n",
      "Epoch 9/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.4534 - acc: 0.9316 - val_loss: 1.5125 - val_acc: 0.4071\n",
      "Epoch 10/10\n",
      "5187/5187 [==============================] - 4s - loss: 0.4409 - acc: 0.9354 - val_loss: 1.5849 - val_acc: 0.3917\n",
      "Train on 182 samples, validate on 46 samples\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 0s - loss: 1.7523 - acc: 0.2747 - val_loss: 1.8002 - val_acc: 0.3913\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s - loss: 0.6785 - acc: 0.8516 - val_loss: 1.6928 - val_acc: 0.3043\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s - loss: 0.4981 - acc: 0.9451 - val_loss: 1.6151 - val_acc: 0.3261\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s - loss: 0.4227 - acc: 0.9835 - val_loss: 1.5712 - val_acc: 0.3261\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s - loss: 0.3974 - acc: 0.9615 - val_loss: 1.5784 - val_acc: 0.3261\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s - loss: 0.3780 - acc: 0.9615 - val_loss: 1.5219 - val_acc: 0.3043\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s - loss: 0.3774 - acc: 0.9725 - val_loss: 1.5423 - val_acc: 0.3261\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s - loss: 0.3776 - acc: 0.9725 - val_loss: 1.5549 - val_acc: 0.3261\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s - loss: 0.3581 - acc: 0.9725 - val_loss: 1.5164 - val_acc: 0.3261\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s - loss: 0.3524 - acc: 0.9725 - val_loss: 1.5081 - val_acc: 0.3261\n",
      "Train on 3188 samples, validate on 797 samples\n",
      "Epoch 1/10\n",
      "3188/3188 [==============================] - 2s - loss: 1.9818 - acc: 0.3403 - val_loss: 1.9561 - val_acc: 0.4153\n",
      "Epoch 2/10\n",
      "3188/3188 [==============================] - 2s - loss: 1.6520 - acc: 0.5125 - val_loss: 1.9306 - val_acc: 0.3714\n",
      "Epoch 3/10\n",
      "3188/3188 [==============================] - 2s - loss: 1.4280 - acc: 0.6242 - val_loss: 1.9232 - val_acc: 0.3350\n",
      "Epoch 4/10\n",
      "3188/3188 [==============================] - 2s - loss: 1.2612 - acc: 0.7221 - val_loss: 1.9410 - val_acc: 0.3538\n",
      "Epoch 5/10\n",
      "3188/3188 [==============================] - 3s - loss: 1.1597 - acc: 0.7594 - val_loss: 1.9197 - val_acc: 0.3764\n",
      "Epoch 6/10\n",
      "3188/3188 [==============================] - 3s - loss: 1.0761 - acc: 0.8077 - val_loss: 1.9446 - val_acc: 0.3739\n",
      "Epoch 7/10\n",
      "3188/3188 [==============================] - 2s - loss: 1.0287 - acc: 0.8055 - val_loss: 1.9526 - val_acc: 0.4053\n",
      "Epoch 8/10\n",
      "3188/3188 [==============================] - 2s - loss: 1.0005 - acc: 0.8127 - val_loss: 1.9687 - val_acc: 0.3827\n",
      "Epoch 9/10\n",
      "3188/3188 [==============================] - 3s - loss: 0.9755 - acc: 0.8181 - val_loss: 1.9833 - val_acc: 0.4191\n",
      "Epoch 10/10\n",
      "3188/3188 [==============================] - 2s - loss: 0.9600 - acc: 0.8281 - val_loss: 2.0150 - val_acc: 0.4329\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(None)\n",
    "for i in range(1, 7):\n",
    "    model = build_model(4)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[i], y[i], test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train, nb_epoch=10, batch_size=64, verbose=1, validation_data=(X_test, y_test))\n",
    "    model.save('models/note_model_{0}.h5'.format(i))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
