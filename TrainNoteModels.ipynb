{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import gc\n",
    "import math\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from numpy import median, diff\n",
    "from xgboost import XGBClassifier\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOS\n",
    "- generate percent of single double notes etc with a nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "- 1: one note\n",
    "- 2: two notes\n",
    "- 3: three or four notes\n",
    "- 4: hold start\n",
    "- 5: roll start\n",
    "- 6: mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_for_index_expanded(notes, index):\n",
    "    if index < 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    row = notes[index][0]\n",
    "    (steps, holds, rolls, mines) = [row.count(char) for char in ['1', '2', '4', 'M']]\n",
    "    if steps == 0 and mines == 0 and holds == 0 and rolls == 0:\n",
    "        return [1, 0, 0, 0, 0, 0, 0]\n",
    "    steps += (holds + rolls)\n",
    "    return [int(i) for i in [False, steps == 1, steps == 2, steps > 2, holds > 0, rolls > 0, mines > 0]]\n",
    "\n",
    "def get_class_for_index(notes, index):\n",
    "    classes_expanded = get_class_for_index_expanded(notes, index)\n",
    "    return [i for i in range(7) if classes_expanded[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps_per_bar = 48\n",
    "class SongFile:\n",
    "    def __init__(self, key):\n",
    "        misc = pd.read_csv('data/{0}_misc.csv'.format(key)).values\n",
    "        self.bpm = misc[1][0]\n",
    "        self.notes = pd.read_csv('data/{0}_notes.csv'.format(key), converters={'0': lambda x: str(x)}).values\n",
    "        self.note_classes = [get_class_for_index_expanded(self.notes, i) for i in range(len(self.notes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beats_to_track = 48\n",
    "note_types = ['0', '1', 'M', '2', '4', '3']\n",
    "\n",
    "def get_features_for_row(row):\n",
    "    return [int(char == target) for target in note_types for char in row]\n",
    "\n",
    "empty_row = [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "def get_previous_notes(index, features):\n",
    "    previous_notes = [features[i] for i in range(index, index + song_padding) if not np.array_equal(features[i], empty_row)]\n",
    "    return [empty_row] * (8 - len(previous_notes)) + previous_notes[-8:]\n",
    "    \n",
    "song_padding = beats_to_track * 2\n",
    "song_end_padding = beats_to_track * 2\n",
    "important_indices = [1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "important_indices_classes = [-96, -84, -72, -60, -48, -36, -24, -12, 0, 1, 2, 3, 4, 8, 16, 20, 6, 12, 18, 24, 30, 36, 42, 48, 54, 60, 66, 72, 78, 84, 90, 96]\n",
    "def get_features(index, features, note_classes):\n",
    "    indices = [index + song_padding - i for i in important_indices]\n",
    "    indices_classes = [index + song_padding - i for i in important_indices_classes]\n",
    "    past_classes = np.array([note_classes[i] for i in indices_classes]).flatten()\n",
    "    past_features = np.array([features[i] for i in indices]).flatten()\n",
    "    previous_notes = np.array(get_previous_notes(index, features)).flatten()\n",
    "    return np.concatenate((past_classes, past_features, previous_notes), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_output_for_class(model_class, row):\n",
    "    if model_class == 1 or model_class == 2 or model_class == 3:\n",
    "        return [int(char == '1' or char == '2' or char == '4') for char in row]\n",
    "    if model_class == 4:\n",
    "        return [int(char == '2') for char in row]\n",
    "    if model_class == 5:\n",
    "        return [int(char == '4') for char in row]\n",
    "    if model_class == 6:\n",
    "        return [int(char == 'M') for char in row]\n",
    "\n",
    "def get_hold_length(notes, note_row, note_column):\n",
    "    i = 0\n",
    "    while i < len(notes) - note_row:\n",
    "        if notes[note_row + i][0][note_column] == '3':\n",
    "            return i\n",
    "        i += 1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_features_for_songs(songs):\n",
    "    hold_X = []\n",
    "    roll_X = []\n",
    "    hold_y = []\n",
    "    roll_y = []\n",
    "    X = [[] for i in range(6)]\n",
    "    y = [[] for i in range(6)]\n",
    "    for song in songs:\n",
    "        note_classes = np.concatenate((([[1, 0, 0, 0, 0, 0, 0]] * song_padding), song.note_classes, ([[1, 0, 0, 0, 0, 0, 0]] * song_end_padding)), axis = 0)\n",
    "        notes = np.concatenate((([['0000']] * song_padding), song.notes), axis = 0)\n",
    "        if abs(len(note_classes) - len(notes) > 250):\n",
    "            print ('Lengths dont match for {0}'.format(key))\n",
    "            print ('{0} vs {1}'.format(len(note_classes), len(notes)))\n",
    "            continue\n",
    "        length = min(len(note_classes) - song_padding - song_end_padding, len(notes) - song_padding)\n",
    "        features = np.array([get_features_for_row(notes[i][0]) for i in range(0, length + song_padding)])\n",
    "        for i in range(length):\n",
    "            row = notes[i + song_padding][0]\n",
    "            model_classes = get_class_for_index(notes, i + song_padding)\n",
    "            for model_class in model_classes:\n",
    "                X_row = get_features(i, features, note_classes)\n",
    "                X[model_class].append(X_row)\n",
    "                y[model_class].append(get_model_output_for_class(model_class, row))\n",
    "                if model_class == 4:\n",
    "                    for j in range(4):\n",
    "                        if row[j] == '2':\n",
    "                            length = get_hold_length(notes, i + song_padding, j)\n",
    "                            if length:\n",
    "                                hold_X.append(X_row)\n",
    "                                hold_y.append(length)\n",
    "                if model_class == 5:\n",
    "                    for j in range(4):\n",
    "                        if row[j] == '4':\n",
    "                            length = get_hold_length(notes, i + song_padding, j)\n",
    "                            if length:\n",
    "                                roll_X.append(X_row)\n",
    "                                roll_y.append(length)\n",
    "\n",
    "    X = [np.array(X_for_class) for X_for_class in X]\n",
    "    y = [np.array(y_for_class) for y_for_class in y]\n",
    "    return X, y, np.array(hold_X), np.array(hold_y), np.array(roll_X), np.array(roll_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs_to_use_full = pd.read_csv('data/songs_to_use.csv').values\n",
    "save_files = listdir('data')\n",
    "songs_to_use = [song_data for song_data in songs_to_use_full if '{0}_misc.csv'.format(song_data[0]) in save_files]\n",
    "songs = [SongFile(song_data[0]) for song_data in songs_to_use]\n",
    "np.random.shuffle(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 48s, sys: 14 s, total: 11min 2s\n",
      "Wall time: 11min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_array, y_train_array, hold_X_train, hold_y_train, roll_X_train, roll_y_train = get_features_for_songs(songs[:174]) # total 217\n",
    "X_test_array, y_test_array, hold_X_test, hold_y_test, roll_X_test, roll_y_test = get_features_for_songs(songs[174:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_lengths = [3, 6, 9, 12, 18, 24, 36, 48]\n",
    "def get_closest_hold_lengths(lengths):\n",
    "    closest = [np.argmax([-abs(length - aprox) for aprox in hold_lengths]) for length in lengths]\n",
    "    closest_one_hot = np.zeros((len(closest), len(hold_lengths)))\n",
    "    closest_one_hot[np.arange(len(closest)), closest] = 1\n",
    "    return np.array(closest_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_y_train_backup_array = hold_y_train_array\n",
    "roll_y_train_backup_array = roll_y_train_array\n",
    "hold_y_test_backup_array = hold_y_test_array\n",
    "roll_y_test_backup_array = roll_y_test_array\n",
    "hold_y_train_array = get_closest_hold_lengths(hold_y_train_backup_array)\n",
    "roll_y_train_array = get_closest_hold_lengths(roll_y_train_backup_array)\n",
    "hold_y_test_array = get_closest_hold_lengths(hold_y_test_backup_array)\n",
    "roll_y_test_array = get_closest_hold_lengths(roll_y_test_backup_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1024, input_shape=(968,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adagrad',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6977 samples, validate on 1637 samples\n",
      "Epoch 1/5\n",
      "6977/6977 [==============================] - 2s - loss: 1.7676 - acc: 0.3841 - val_loss: 1.8668 - val_acc: 0.3158\n",
      "Epoch 2/5\n",
      "6977/6977 [==============================] - 2s - loss: 1.4505 - acc: 0.5199 - val_loss: 1.7549 - val_acc: 0.3965\n",
      "Epoch 3/5\n",
      "6977/6977 [==============================] - 2s - loss: 1.3247 - acc: 0.5759 - val_loss: 1.6736 - val_acc: 0.4264\n",
      "Epoch 4/5\n",
      "6977/6977 [==============================] - 2s - loss: 1.2196 - acc: 0.6219 - val_loss: 1.6354 - val_acc: 0.4386\n",
      "Epoch 5/5\n",
      "6977/6977 [==============================] - 2s - loss: 1.1336 - acc: 0.6531 - val_loss: 1.6109 - val_acc: 0.4417\n"
     ]
    }
   ],
   "source": [
    "model = build_model(len(hold_lengths))\n",
    "model.fit(hold_X_train, hold_y_train, nb_epoch=5, batch_size=64, verbose=1, validation_data=(hold_X_test, hold_y_test))\n",
    "model.save('models/hold_length_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 192 samples, validate on 70 samples\n",
      "Epoch 1/5\n",
      "192/192 [==============================] - 0s - loss: 1.9776 - acc: 0.2552 - val_loss: 2.2029 - val_acc: 0.1714\n",
      "Epoch 2/5\n",
      "192/192 [==============================] - 0s - loss: 1.1365 - acc: 0.7240 - val_loss: 2.0339 - val_acc: 0.1857\n",
      "Epoch 3/5\n",
      "192/192 [==============================] - 0s - loss: 0.8839 - acc: 0.8698 - val_loss: 1.9465 - val_acc: 0.2714\n",
      "Epoch 4/5\n",
      "192/192 [==============================] - 0s - loss: 0.7811 - acc: 0.9010 - val_loss: 1.9388 - val_acc: 0.2429\n",
      "Epoch 5/5\n",
      "192/192 [==============================] - 0s - loss: 0.6839 - acc: 0.9531 - val_loss: 1.9223 - val_acc: 0.2143\n"
     ]
    }
   ],
   "source": [
    "model = build_model(len(hold_lengths))\n",
    "model.fit(roll_X_train, roll_y_train, nb_epoch=5, batch_size=64, verbose=1, validation_data=(roll_X_test, roll_y_test))\n",
    "model.save('models/roll_length_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78876 samples, validate on 18412 samples\n",
      "Epoch 1/5\n",
      "78876/78876 [==============================] - 58s - loss: 1.1993 - acc: 0.4197 - val_loss: 1.1624 - val_acc: 0.4378\n",
      "Epoch 2/5\n",
      "78876/78876 [==============================] - 54s - loss: 1.1287 - acc: 0.4699 - val_loss: 1.1536 - val_acc: 0.4430\n",
      "Epoch 3/5\n",
      "78876/78876 [==============================] - 57s - loss: 1.0828 - acc: 0.5023 - val_loss: 1.1605 - val_acc: 0.4426\n",
      "Epoch 4/5\n",
      "78876/78876 [==============================] - 58s - loss: 1.0371 - acc: 0.5342 - val_loss: 1.1845 - val_acc: 0.4369\n",
      "Epoch 5/5\n",
      "78876/78876 [==============================] - 57s - loss: 0.9931 - acc: 0.5596 - val_loss: 1.1808 - val_acc: 0.4390\n",
      "Train on 6031 samples, validate on 1412 samples\n",
      "Epoch 1/5\n",
      "6031/6031 [==============================] - 14s - loss: 2.7893 - acc: 0.2742 - val_loss: 2.7565 - val_acc: 0.2075\n",
      "Epoch 2/5\n",
      "6031/6031 [==============================] - 13s - loss: 2.6909 - acc: 0.3203 - val_loss: 2.7774 - val_acc: 0.2323\n",
      "Epoch 3/5\n",
      "6031/6031 [==============================] - 11s - loss: 2.6090 - acc: 0.3552 - val_loss: 2.8230 - val_acc: 0.2309\n",
      "Epoch 4/5\n",
      "6031/6031 [==============================] - 11s - loss: 2.5031 - acc: 0.3888 - val_loss: 2.8979 - val_acc: 0.2606\n",
      "Epoch 5/5\n",
      "6031/6031 [==============================] - 11s - loss: 2.3960 - acc: 0.4147 - val_loss: 2.9679 - val_acc: 0.2741\n",
      "Train on 26 samples, validate on 24 samples\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 0s - loss: 5.6991 - acc: 0.1154 - val_loss: 5.9513 - val_acc: 0.0417\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 0s - loss: 5.5193 - acc: 0.1538 - val_loss: 6.1486 - val_acc: 0.6667\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 0s - loss: 5.5869 - acc: 0.1154 - val_loss: 5.3361 - val_acc: 0.6250\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 0s - loss: 5.3687 - acc: 0.0000e+00 - val_loss: 5.5820 - val_acc: 0.6667\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 0s - loss: 5.3224 - acc: 0.2692 - val_loss: 5.2542 - val_acc: 0.2500\n",
      "Train on 6629 samples, validate on 1601 samples\n",
      "Epoch 1/5\n",
      "6629/6629 [==============================] - 14s - loss: 1.4206 - acc: 0.3666 - val_loss: 1.3436 - val_acc: 0.4054\n",
      "Epoch 2/5\n",
      "6629/6629 [==============================] - 13s - loss: 1.2428 - acc: 0.4868 - val_loss: 1.3671 - val_acc: 0.3935\n",
      "Epoch 3/5\n",
      "6629/6629 [==============================] - 13s - loss: 1.0889 - acc: 0.5779 - val_loss: 1.3991 - val_acc: 0.3823\n",
      "Epoch 4/5\n",
      "6629/6629 [==============================] - 13s - loss: 0.9423 - acc: 0.6619 - val_loss: 1.4258 - val_acc: 0.3791\n",
      "Epoch 5/5\n",
      "6629/6629 [==============================] - 13s - loss: 0.8202 - acc: 0.7398 - val_loss: 1.4689 - val_acc: 0.3679\n",
      "Train on 190 samples, validate on 63 samples\n",
      "Epoch 1/5\n",
      "190/190 [==============================] - 1s - loss: 1.4807 - acc: 0.3211 - val_loss: 1.6761 - val_acc: 0.2698\n",
      "Epoch 2/5\n",
      "190/190 [==============================] - 1s - loss: 1.2423 - acc: 0.4632 - val_loss: 1.6633 - val_acc: 0.2540\n",
      "Epoch 3/5\n",
      "190/190 [==============================] - 1s - loss: 1.0860 - acc: 0.5579 - val_loss: 1.6815 - val_acc: 0.2222\n",
      "Epoch 4/5\n",
      "190/190 [==============================] - 1s - loss: 0.9448 - acc: 0.5895 - val_loss: 1.7169 - val_acc: 0.2540\n",
      "Epoch 5/5\n",
      "190/190 [==============================] - 1s - loss: 0.8888 - acc: 0.6474 - val_loss: 1.8561 - val_acc: 0.2698\n",
      "Train on 3565 samples, validate on 905 samples\n",
      "Epoch 1/5\n",
      "3565/3565 [==============================] - 14s - loss: 1.9632 - acc: 0.3307 - val_loss: 1.8989 - val_acc: 0.3171\n",
      "Epoch 2/5\n",
      "3565/3565 [==============================] - 14s - loss: 1.7777 - acc: 0.4648 - val_loss: 1.9034 - val_acc: 0.3492\n",
      "Epoch 3/5\n",
      "3565/3565 [==============================] - 14s - loss: 1.6650 - acc: 0.5094 - val_loss: 1.9813 - val_acc: 0.3370\n",
      "Epoch 4/5\n",
      "3565/3565 [==============================] - 14s - loss: 1.5563 - acc: 0.5683 - val_loss: 2.0576 - val_acc: 0.3204\n",
      "Epoch 5/5\n",
      "3565/3565 [==============================] - 15s - loss: 1.4802 - acc: 0.5935 - val_loss: 2.0986 - val_acc: 0.3171\n",
      "CPU times: user 14min 46s, sys: 58.3 s, total: 15min 44s\n",
      "Wall time: 8min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_sizes = [0, 64, 16, 2, 16, 4, 8]\n",
    "models = []\n",
    "models.append(None)\n",
    "for X_train, y_train, X_test, y_test in zip():\n",
    "    model = build_model(4)\n",
    "    model.fit(X_train[i], y_train[i], nb_epoch=5, batch_size=batch_sizes[i], verbose=1, validation_data=(X_test[i], y_test[i]))\n",
    "    model.save('models/note_model_{0}.h5'.format(i))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_arrays = [\n",
    "    [],\n",
    "    ['1000', '0100', '0010', '0001'],\n",
    "    ['1100', '1010', '1001', '0110', '0101', '0011'],\n",
    "    ['1110', '1101', '1011', '0111', '1111'],\n",
    "    ['1000', '0100', '0010', '0001', '2', '3', '4'],\n",
    "    ['1000', '0100', '0010', '0001', '2', '3', '4'],\n",
    "    ['1000', '0100', '0010', '0001', '2', '3', '4'],\n",
    "]\n",
    "class_maps = [dict((class_array[i], i) for i in range(len(class_array))) for class_array in class_arrays]\n",
    "def get_class(class_map, y_row):\n",
    "    as_string = ''.join(str(x) for x in y_row)\n",
    "    pos_count = as_string.count('1')\n",
    "    return class_map[str(pos_count)] if '2' in class_map and pos_count > 1 else class_map[as_string]\n",
    "\n",
    "def get_y_not_one_hot(y):\n",
    "    return [[get_class(class_map, y_row) for y_row in y_section] for class_map, y_section in zip(class_maps[1:], y[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_classes = get_y_not_one_hot(y_train)\n",
    "y_test_classes = get_y_not_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999188599828\n",
      "0.451499022377\n",
      "1.0\n",
      "0.235127478754\n",
      "1.0\n",
      "0.25\n",
      "1.0\n",
      "0.425359150531\n",
      "1.0\n",
      "0.285714285714\n",
      "1.0\n",
      "0.339226519337\n",
      "CPU times: user 48.5 s, sys: 2.54 s, total: 51.1 s\n",
      "Wall time: 54.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "min_samples_leafs = [0, 32, 8, 1, 8, 2, 4]\n",
    "rfs = []\n",
    "rfs.append(None)\n",
    "for train, train_y, test, test_y in zip(X_train[1:], y_train_classes, X_test[1:], y_test_classes):\n",
    "    rf_clf = RandomForestClassifier(n_estimators = 50) #, min_samples_leaf=min_samples_leafs[i])\n",
    "    rf_clf.fit(train, train_y)\n",
    "    print (rf_clf.score(train, train_y))\n",
    "    print (rf_clf.score(test, test_y))\n",
    "    rfs.append(rf_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (78876, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-189-1a84e33c1808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sgds = []\\nsgds.append(None)\\nfor i in range(1, 7):\\n    sgd_clf = SGDClassifier(loss=\"modified_huber\", n_iter=10)\\n    sgd_clf.fit(X_train[i], y_train[i])\\n    print (sgd_clf.score(X_train[i], y_train[i]))\\n    print (sgd_clf.score(X_test[i], y_test[i]))\\n    sgds.append(sgd_clf)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    543\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    513\u001b[0m                         dtype=None)\n\u001b[1;32m    514\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (78876, 4)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sgds = []\n",
    "sgds.append(None)\n",
    "for i in range(0, 6):\n",
    "    sgd_clf = SGDClassifier(loss=\"modified_huber\", n_iter=10)\n",
    "    sgd_clf.fit(X_train[i], y_train_classes[i])\n",
    "    print (sgd_clf.score(X_train[i], y_train_classes[i]))\n",
    "    print (sgd_clf.score(X_test[i], y_test_classes[i]))\n",
    "    sgds.append(sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (78876, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-02b372a4afb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'xgbs = []\\nxgbs.append(None)\\nfor i in range(1, 7):\\n    xgb_clf = XGBClassifier(max_depth=7, min_child_weight=8, learning_rate=0.05, seed=0, n_estimators=100, subsample=0.80, colsample_bytree=0.80, objective=\"multi:softprob\")\\n    xgb_clf.fit(X_train[i], y_train[i])\\n    print (xgb_clf.score(X_train[i], y_train[i]))\\n    print (xgb_clf.score(X_test[i], y_test[i]))\\n    xgbs.append(xgb_clf)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0mxgb_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"eval_metric\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0m_check_numpy_unicode_bug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jgzuke/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (78876, 4)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgbs = []\n",
    "xgbs.append(None)\n",
    "for i in range(0, 6):\n",
    "    xgb_clf = XGBClassifier(max_depth=7, min_child_weight=8, learning_rate=0.05, seed=0, n_estimators=100, subsample=0.80, colsample_bytree=0.80, objective=\"multi:softprob\")\n",
    "    xgb_clf.fit(X_train[i], y_train_classes[i])\n",
    "    print (xgb_clf.score(X_train[i], y_train_classes[i]))\n",
    "    print (xgb_clf.score(X_test[i], y_test_classes[i]))\n",
    "    xgbs.append(xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
